---
title: "Analysis Script"
author: "Shaina Trevino"
date: "2023-02-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install and load pacman package
if (!require("pacman")) install.packages("pacman")

#install and load required packages
p_load(devtools, here, readxl, janitor, tidyverse, openxlsx, robumeta, metafor, lubridate, gt, webshot2, DiagrammeR, prismadiagramR, stringi, htmltools, bib2df) 
p_load_gh("thdiakon/ccaR", "mcguinlu/robvis") #from github

```

## Overview

This document produces all the results reported in our technical report: "School-Based Interventions for Primary and Secondary Prevention of Depression: An Overview of Systematic Reviews with Meta-Analyses." The first two sections are importing and data cleaning code followed by code to reproduce our results. Code is presented in the order in which results are presented in the report starting with narrative results, followed by tables, figures, and appendices. Each section has a header that corresponds with the headers in the report. 

## Import

Import review-level reference and eligibility screening data in `Depression_Overview_Search_Data.xlsx`
* `reference_level`: One row per reference ID screened, abstract and eligibility decisions (all imported review citations)
* `review_bib`: One row per eligible review, main citation from Zotero for eligible reviews

```{r import-reference-level}
#set path to search data
search_path <- (here("data", "Depression_Overview_Search_Data.xlsx"))

#import reference_level excel sheet
reference_level <- read_excel(search_path, sheet = "reference_level",
                                      guess_max = 123456) 

#import Zotero reference information for eligible reviews
review_bib <- bib2df(here("data", "included_reviews.bib")) %>% 
  janitor::clean_names()

```

Import primary study reference and eligibility screening data from `Depression_Overview_Eligibility_Data.xlsx`
 * `eligibility_decisions`: One row per primary study, data for eligibility decisions and reasons for exclude, when applicable
 * `reports`: One row per reference, data for multiple reports/citations of a single primary study, when applicable
 * `citation_matrix`: One row per primary study, data on primary study overlap (which primary studies were included in each review)

```{r import-pselig}
#set path to eligibility data
elig_path <- here("data", "Depression_Overview_Eligibility_Data.xlsx")

#import eligibility_decisions sheet of excel file 
ps_eligibility <- read_excel(elig_path, sheet = "eligibility_decisions") 

#import excel primary study reference sheet
ps_allreferences <- read_excel(elig_path, sheet = "reports") 

#import excel citation matrix (with header to calculate # of included/eligible studies)
ps_cm <- read_excel(elig_path, sheet = "citation_matrix")

#import excel citation matrix sheet (without header to transpose for lists of included/eligible reviews)
citation_matrix <- read_excel(elig_path, sheet = "citation_matrix", col_names = FALSE)

#import main primary study reference from Zotero .bib export
bib_ps_df <- bib2df(here("data", "included_studies.bib")) %>% 
  janitor::clean_names()

```


Import reconciled, review-level data in `Depression_Overview_Review_Data.xlsx`
* `review_level`: One row per full-text-eligible review ID, extracted descriptive data at the review level
* `review_amstar`: One row per full-text-eligible review ID, extracted quality study assessment (AMSTAR) data
* `review_robis`: One row per full-text-eligible review ID, extracted risk of bias (ROBIS) data

```{r import-review}
#set path to review-level data
rd_path <- here("data", "Depression_Overview_Review_Data.xlsx")

#import review level descriptive data
review_level <- read_excel(rd_path, sheet = "review_level")

#import review level quality study assessment data
review_amstar <- read_excel(rd_path, sheet = "amstar")

#import review level risk of bias data
review_robis <- read_excel(rd_path, sheet = "robis") 

```

Import reconciled, primary study level data in `Depression_Overview_Study_Data.xlsx`
* `study_level`: One row per eligible primary study, extracted descriptive data for each included primary study
* `study_irob`: One row per eligible primary study, extracted risk of bias data for individually-randomized studies
* `study_crob`: One row per eligible primary study, extracted descriptive data for cluster-randomized studies
* `study_robins`: One row per eligible primary study, extracted descriptive data for applicable non-randomized studies
* `group_level`: One row per user-created group ID, extracted descriptive data for each trial group in primary studies
* `outcome_level`: One row per user-created outcome ID, extracted descriptive for each outcome of interest in primary studies

```{r import-study}
#set path to study-level data
sd_path <- here("data", "Depression_Overview_Primary_Study_Data.xlsx")

#import primary study level descriptive data
study_level <- read_excel(sd_path, sheet = "study_level")

#import study level risk of bias data for individual RCTs
study_irob <- read_excel(sd_path, sheet = "iROB")

#import study level risk of bias data for cluster RCTs
study_crob <- read_excel(sd_path, sheet = "cROB")

#import study level risk of bias data for non-randomized trials
study_robins <- read_excel(sd_path, sheet = "ROBINS-I")

#import group level descriptive data
group_level <- read_excel(sd_path, sheet = "group_level")

#import outcome level descriptive data
outcome_level <- read_excel(sd_path, sheet = "outcome_level") 

```

Import cleaned, meta-analysis data in `Depression_Overview_MetaAnalysis_Data.xlsx`
* Effect size data for each included primary study
* Each outcome of interest is in a separate tab (e.g., depression diagnosis)
* One row per group comparison and outcome combination (intervention + comparison + outcome)

```{r import-ma}
#set path to effect size data for meta-analyses
ma_path <- here("data", "Depression_Overview_Meta_Analysis_Data.xlsx")

#import effect size data for depression diagnosis
depression_diagnosis <- read_excel(ma_path, sheet = "Depression Diagnosis")

#import effect size data for depression symptoms
depression_symptoms <- read_excel(ma_path, sheet = "Depression Symptoms")

#import effect size data for anxiety
anxiety_symptoms <- read_excel(ma_path, sheet = "Anxiety")

#import effect size data for subsyndromal depression
subsyndromal_depression <- read_excel(ma_path, sheet = "Subsyndromal Depression")

#import effect size data for educational achievement
edu_achievement <- read_excel(ma_path, sheet = "Educational Achievement")

#import effect size data for self-harm
self_harm <- read_excel(ma_path, sheet = "Self Harm")

#import effect size data for stress
stress <- read_excel(ma_path, sheet = "Stress")

#import effect size data for substance use
substance_use <- read_excel(ma_path, sheet = "Substance Use")

#import effect size data for suicidal ideation
suicidal_ideation <- read_excel(ma_path, sheet = "Suicidal Ideation")

#import effect size data for well-being
well_being <- read_excel(ma_path, sheet = "Well-being")
```

## Pre-processing

Reference Level:
* add leading numbers to all eligibility criteria reasons since some responses did not have them

```{r tidy-reference}
#add leading numbers to harmonize responses
td_reference <- reference_level %>%
  mutate(exclude_reason = case_when(exclude_reason == "Ineligible due to anxiety focus only" ~
                                            "01. Ineligible due to anxiety focus only",
                                          exclude_reason == "Ineligible population (not K-12 students)" ~
                                            "02. Ineligible population (not K-12 students)",
                                          exclude_reason == "Ineligible interventions (not universal or secondary prevention)" ~
                                            "03. Ineligible interventions (not universal or secondary prevention)",
                                          exclude_reason == "Ineligible comparator (no comparator)" ~
                                            "04. Ineligible comparator (no comparator)",
                                          exclude_reason == "Ineligible outcomes (no depression outcomes)" ~
                                            "05. Ineligible outcomes (no depression outcomes)",
                                          exclude_reason == "Ineligible setting (not in school settings)" ~
                                            "07. Ineligible setting (not in school settings)",
                                          exclude_reason == "Ineligible study design (not a systematic review)" ~
                                            "08. Ineligible study design (not a systematic review)",
                                          exclude_reason == "Ineligible study design (no meta-analysis)" ~
                                            "09. Ineligible study design (no meta-analysis)",
                                          exclude_reason == "Ineligible publication type (not a full report)" ~
                                            "10. Ineligible publication type (not a full report)",
                                          exclude_reason == "Other reason (please specify in notes)" ~
                                            "11. Other reason (please specify in notes)",
                                          TRUE ~ exclude_reason)) %>%
  mutate_if(is.character, as.factor)

```

Review Level:
* create a new variable to identify reviews (extract author's last name and paste it with the year of publication)
* pull a list of the included reviews to use for filtering and merging
* merge review names into risk of bias data

```{r tidy-review}
#create variable for author/year
td_review <- review_level %>% 
  mutate(review_author_lastname = str_extract(review_author_name, '\\w+$'),
         review_author_year = paste(review_author_lastname, review_year, sep = " ")) %>% 
  mutate(review_author_year = case_when(review_author_year == "Seidler 2017" ~ "Werner-Seidler 2017",
                                       review_author_year == "Seidler 2021" ~ "Werner-Seidler 2021",
                                       review_author_year == "Zoonen 2014" ~ "van Zoonen 2014",
                                       TRUE ~ review_author_year)) #correct parsing errors

#create data frame of review ids and review names (author/year)
review_idbyname <- td_review %>% 
  select(review_id, review_author_year)

#pull list of included reviews
inc_rev <- review_idbyname$review_author_year

#merge review names into review_amstar data
td_amstar <- review_amstar %>% 
  left_join(review_idbyname) %>% 
  select(review_author_year, everything()) %>% 
  arrange(review_author_year) 

#merge review names into review_robis data
td_robis <- review_robis %>%
  left_join(review_idbyname) %>%
  select(review_author_year, everything()) %>%
  arrange(review_author_year)

```

Primary Study Eligibility Level: 
* pull list of primary studies that are included in our meta-analyses (eligible studies)
* factor and rename the study name variable in the `citation_matrix` to match all other files

```{r tidy-pseligibility}
#create object to match revision code 
ps_elig_td <- ps_eligibility

#pull list of included studies
inc_ps <- ps_eligibility %>% 
  filter(decision == "Include") %>% 
  pull(study) 

#create object to match revision code
td_cm <- ps_cm

```

Primary Study Level:
* specify numeric variable types for calculations
* for numeric variables, specify that -999 is missing for calculations
* extract a data frame of study ids and study names for merging

```{r tidy-study}
#clean study level data
td_study <- study_level %>% 
  arrange(str_to_lower(study_author_year)) %>% 
  mutate(cluster_size = as.numeric(cluster_size)) %>% 
  mutate_if(is.numeric, ~ if_else(. == -999, NA_real_, .))
  
#extract study id and study names
study_idbyname <- td_study %>% 
  select(primary_study_id, study_author_year)

#select variables for irob ratings
irob_df <- study_irob %>%
  select(primary_study_id, ends_with("judgment"), iROB_overall_rating)

#select variables for crob ratings
crob_df <- study_crob %>%
  select(primary_study_id, ends_with("judgment"), cROB_overall_rating)

#select variables for robins-i info
robins_df <- study_robins %>%
  select(primary_study_id, ends_with("judgment"), robins_overall_rating)
  
```

Group Level: 
* correct `intervention_intensity` variable to be the average when a range was extracted
* specify numeric variable types for calculations

```{r tidy-group}
#correct intervention intensity variable
td_group <- group_level %>% 
  mutate(intervention_intensity = case_when(intervention_intensity == "20 to 30" ~ "50",
                                            intervention_intensity == "20 to 40" ~ "30",
                                            intervention_intensity == "20 to 40" ~ "30",
                                            intervention_intensity == "20 to 60" ~ "40",
                                            intervention_intensity == "30 to 60" ~ "45",
                                            intervention_intensity == "30 to 90" ~ "60",
                                            intervention_intensity == "35 to 60" ~ "47.5",
                                            intervention_intensity == "35 to 40" ~ "37.5",
                                            intervention_intensity == "40 to 60" ~ "50",
                                            intervention_intensity == "40 to 45" ~ "42.5",
                                            intervention_intensity == "40 to 50" ~ "45",
                                            intervention_intensity == "45 to 50" ~ "47.5",
                                            intervention_intensity == "45 to 50" ~ "47.5",
                                            intervention_intensity == "45 to 60" ~ "52.5",
                                            intervention_intensity == "45 to 90" ~ "67.5",
                                            intervention_intensity == "50 to 60" ~ "55",
                                            TRUE ~ intervention_intensity)) %>%
  mutate(intervention_intensity = as.numeric(intervention_intensity),
         intervention_frequency = ifelse(intervention_frequency == "6. Cannot Tell", "-999", intervention_frequency)) %>% 
  mutate_if(is.numeric, ~ if_else(. == -999, NA_real_, .)) 

```

Outcome Level:
* transform study ID variable to numeric
* create cleaned outcome measure variable that collapses same measures that have different versions
* create function that will clean outcome_measures across different data sets (e.g., meta-analysis files)

```{r tidy-outcome}
#make study ID numeric and create variable that aggregates outcome measures
td_outcome <- outcome_level %>% 
  mutate(primary_study_id = as.numeric(primary_study_id)) %>% 
  mutate(outcome_measure_lc = str_to_lower(outcome_measure),
         agg_outcome_meas = case_when(str_detect(outcome_measure_lc, "beck depression inventory") ~ 
                                        "Beck Depression Inventory",
                                      str_detect(outcome_measure_lc, "center for epidemiologic studies depression scale") ~ 
                                        "Center for Epidemiologic Studies Depression Scale",
                                      str_detect(outcome_measure_lc, "children") & str_detect(outcome_measure_lc, "depression inventory") ~ 
                                        "Children’s Depression Inventory",
                                      str_detect(outcome_measure_lc, "revised children’s manifest anxiety scale") ~ 
                                        "Revised Children’s Manifest Anxiety Scale",
                                      str_detect(outcome_measure_lc, "mood and feelings questionnaire") ~ 
                                        "Mood and Feelings Questionnaire",
                                      str_detect(outcome_measure_lc, "depression anxiety stress scale") ~ 
                                        "Depression Anxiety Stress Scale",
                                      str_detect(outcome_measure_lc, "reynolds adolescent depression scale") ~ 
                                        "Reynolds Adolescent Depression Scale",
                                      str_detect(outcome_measure_lc, "spence") & str_detect(outcome_measure_lc, "anxiety scale") ~ 
                                      "Spence Children's Anxiety Scale",
                                      str_detect(outcome_measure_lc, "structured clinical interview") ~ "Structured Clinical Interview",
                                      TRUE ~ outcome_measure))

#create function to clean outcome_measure variable
mutate_outcome_measure <- function(df){
  df %>% 
  mutate(outcome_measure_lc = str_to_lower(outcome_measure),
         agg_outcome_meas = case_when(str_detect(outcome_measure_lc, "beck depression inventory") ~ 
                                        "Beck Depression Inventory",
                                      str_detect(outcome_measure_lc, "center for epidemiologic studies depression scale") ~ 
                                        "Center for Epidemiologic Studies Depression Scale",
                                      str_detect(outcome_measure_lc, "children") & str_detect(outcome_measure_lc, "depression inventory") ~ 
                                        "Children’s Depression Inventory",
                                      str_detect(outcome_measure_lc, "revised children’s manifest anxiety scale") ~ 
                                        "Revised Children’s Manifest Anxiety Scale",
                                      str_detect(outcome_measure_lc, "mood and feelings questionnaire") ~ 
                                        "Mood and Feelings Questionnaire",
                                      str_detect(outcome_measure_lc, "depression anxiety stress scale") ~ 
                                        "Depression Anxiety Stress Scale",
                                      str_detect(outcome_measure_lc, "reynolds adolescent depression scale") ~ 
                                        "Reynolds Adolescent Depression Scale",
                                      str_detect(outcome_measure_lc, "spence") & str_detect(outcome_measure_lc, "anxiety scale") ~ 
                                      "Spence Children's Anxiety Scale",
                                      str_detect(outcome_measure_lc, "structured clinical interview") ~ "Structured Clinical Interview",
                                      str_detect(outcome_measure_lc, "diagnostic interview for children and adolescents") ~ "Diagnostic Interview for Children and Adolescents",
                                      str_detect(outcome_measure_lc, "reynolds child depression scale") ~ "Reynolds Child Depression Scale",
                                      str_detect(outcome_measure_lc, "revised children's anxiety and depression scale") ~ "Revised Children's Anxiety and Depression Scale", 
                                      str_detect(outcome_measure_lc, "multidimensional anxiety scale for children") ~ "Multidimensional Anxiety Scale for Children",
                                      str_detect(outcome_measure_lc, "children’s automatic thoughts scale") ~ "Children’s Automatic Thoughts Scale",
                                      str_detect(outcome_measure_lc, "stai-ch") ~ "State-Trait Anxiety Inventory for Children",
                                      TRUE ~ outcome_measure))  
}


```

# Analysis Script for Results Section in Report

The following sections are organized to match the order in which results were presented in the report. The code to run the results for the narrative sections are presented first. Followed by the code to produce results for the figures, tables, and appendices.

## Narrative Results

This section includes the code to reproduce results in the narrative results section of the report. Each section heading of this document corresponds exactly to those in the narrative. 

### Eligibility Screening

This section includes code to reproduce the abstract and full-text eligibility screening narrative results section.

Number of records for abstract screening:

```{r elig-imported-refs}
#number of rows in imported references data
nrow(td_reference)

```

Number and percent of retained citations:

```{r elig-kept-citations}
#retained citations
sum(td_reference$screening_consensus == "1. Keep")

#percent out of all citations
sum(td_reference$screening_consensus == "1. Keep") / nrow(td_reference) * 100

```

Number of eligible reviews: 

```{r elig-reviews}
#create dataframe at the review level for reporting # of *reviews*
td_screen_review <- td_reference %>% 
  filter(!is.na(review_id)) %>% 
  distinct(review_id, .keep_all = TRUE)

#number of eligible *reviews*
sum(td_screen_review$eligibility_consensus == "Eligible")

```

Percentage of eligible reviews out of all full-text reviews assessed for eligibility:

```{r elig-review-percent}
#percent of eligible reviews out of all full-texts assessed 
sum(td_screen_review$eligibility_consensus == "Eligible") / sum(td_screen_review$screening_consensus == "1. Keep") * 100

```

Percentage of eligible reviews out of all citations identified: 

```{r elig-review-percent2}
#percent of eligible reviews out of all citations 
sum(td_screen_review$eligibility_consensus == "Eligible") / nrow(td_reference) * 100

```

Number of primary studies included across all reviews: 

```{r elig-study}
#number of primary studies across reviews
nrow(ps_elig_td)

```

Number and percentage of primary studies that met our eligibility criteria: 

```{r elig-inc-stud}
#number of included primary studies
sum(ps_elig_td$decision == "Include")

#percentage 
sum(ps_elig_td$decision == "Include") / nrow(ps_elig_td) * 100

```

### Characteristics of Included Systematic Reviews 

This section includes code to reproduce the characteristics of included systematic reviews narrative results section.

Range and median of publication year across reviews:

```{r review-char-year}
#range and median for year published across reviews
range(review_level$review_year)
median(review_level$review_year)

```

Calculate most commonly searched databases

```{r review-char-databases}
#change string to lowercase and create flag if each database was searched
rev_df <- review_level %>% 
  mutate(databases_searched = str_to_lower(databases_searched),
         pubmed = str_detect(databases_searched, "pubmed"),
         psycinfo = str_detect(databases_searched, "psycinfo"),
         medline = str_detect(databases_searched, "medline"),
         eric = str_detect(databases_searched, "eric"),
         eric2 = str_detect(databases_searched, "education resources information center"),
         ebsco = str_detect(databases_searched, "ebsco"),
         proquest_dt = str_detect(databases_searched, "dissertation and theses"),
         psycarticles = str_detect(databases_searched, "psycarticles"),
         psycextra = str_detect(databases_searched, "psycextra"),
         cochrance_central = str_detect(databases_searched, "cochrane central"),
         cochrane_library = str_detect(databases_searched, "cochrane library"),
         wos = str_detect(databases_searched, "web of science"),
         academic_ap = str_detect(databases_searched, "academic search premier"),
         pbs_collection = str_detect(databases_searched, "psychology and behavioral sciences collection"),
         cinahl = str_detect(databases_searched, "cinahl"),
         embase = str_detect(databases_searched, "embase"),
         science_cit_index = str_detect(databases_searched, "science citation index"),
         sci_direct = str_detect(databases_searched, "science direct"),
         scopus = str_detect(databases_searched, "scopus"),
         gscholar = str_detect(databases_searched, "google scholar"),
         british_ni = str_detect(databases_searched, "british nursing index"),
         britich_ei = str_detect(databases_searched, "british education index"),
         assia = str_detect(databases_searched, "assia"))

#create long dataframe
review_databases <- rev_df %>% 
  select(review_id, pubmed:assia) %>% 
  pivot_longer(cols = pubmed:assia) %>% 
  left_join(review_idbyname) %>% 
  mutate(value = as.character(value))

#calculate most common databases searched and 
#remove cases where reviews said both pubmed and medline but only searched one
mode_databases <- review_databases %>% 
  mutate(name = case_when(name == "eric2" ~ "eric",
                          TRUE ~ name),
         value = case_when(review_author_year == "Bastounis 2016" & name == "medline" ~ "FALSE",
                           review_author_year == "Davaasambuu 2020" & name == "medline" ~ "FALSE",
                           TRUE ~ value)) %>% 
  group_by(name) %>% 
  summarize(num_db = sum(value == "TRUE"),
            percent = sum(value == "TRUE") / nrow(review_level) * 100) %>% 
  arrange(desc(num_db))
mode_databases 

```

Range and median of year of last database search: 

```{r review-char-databaseyear}
#extract year from search data
review_level <- review_level %>% 
  mutate(db_search_year = as.numeric(str_extract(search_date, "[0-9]{4}")))

#calculate range and median
range(review_level$db_search_year, na.rm = TRUE)
median(review_level$db_search_year, na.rm = TRUE)

```

Number and percentage of reviews with PRISMA flow diagrams: 

```{r review-char-prisma}
#number and percent with flow diagrams
sum(review_level$prisma_flow_diagram == "Yes", na.rm = TRUE) 
sum(review_level$prisma_flow_diagram == "Yes", na.rm = TRUE) / nrow(review_level) * 100

```

Number and percentage of reviews that reported a registration number:

```{r review-char-registration}
#number and % with registration number
sum(review_level$review_registration != "-999") 
sum(review_level$review_registration != "-999") / nrow(review_level) * 100 

```

Number and percentage of reviews that had a data availability statement: 

```{r review-char-availability}
#number and % with availability statements
sum(review_level$review_availability_statement != "-999")
sum(review_level$review_availability_statement != "-999") / nrow(review_level) * 100 

```

#### Overlap of Primary Studies Across Systematic Reviews

Range and median of number of primary studies included in each review (using citation matrix data):

```{r numperreview}
#using citation matrix without headers, transpose data 
cmt <- as.data.frame(t(citation_matrix))

#save first row as new column names
colnames(cmt) <- cmt[1,]

#remove first row of column names and second row with current study inclusions
#create new variable to calculate number of studies in each review
df_overlap <- cmt %>% 
  slice(-1:-2) %>% 
  mutate(num_stud = rowSums(. == "1 - Yes")) 

#range and median of number of studies in each review
range(df_overlap$num_stud) 
median(df_overlap$num_stud) 

```

Number and percentage of primary studies included in more than one review:

```{r morethanonereview}
#create flag for if study is in more than one review
cm_overlap <- td_cm %>% 
  select(!`Current Review`) %>% 
  mutate(morethanone = ifelse(rowSums(. == "1 - Yes") >1, "yes", "no"))

#number and % included in more than one review
sum(cm_overlap$morethanone == "yes")
sum(cm_overlap$morethanone == "yes") / nrow(cm_overlap) * 100

```

Number and percentage of eligible primary studies included in more than one review:

```{r elig-morethanone}
#filter for eligible primary studies
elig_cm <- td_cm %>% 
  select(-`Current Review`) %>% 
  filter(study %in% inc_ps) 

#create flag if eligible study is included in more than one review
elig_overlap <- elig_cm %>% 
  mutate(morethanone = ifelse(rowSums(. == "1 - Yes") >1, "yes", "no"))

#number and % of eligible studies included in more than one review
sum(elig_overlap$morethanone == "yes") 
sum(elig_overlap$morethanone == "yes") / nrow(elig_overlap) * 100 

```

Overall CCA percentage for all primary studies included across reviews:

```{r ccaR-overlap}
#create dataframe for ccaR input (1 = included; 0 = excluded)
ccar_input <- td_cm %>% 
  select(-`Current Review`) %>% 
  mutate_at(vars(-study), ~ifelse(. == "1 - Yes", 1, 0))  

#calculate overall CCA
cca(ccar_input) 

```

Overall CCA percentage for primary studies meeting our eligibility criteria:

```{r ccaR-elig}
#filter for only eligible studies
ccar_input_elig <- ccar_input %>% 
  filter(study %in% inc_ps)

#calculate overall CCA
cca(ccar_input_elig) 

```

#### Methodological Quality of Included Systematic Reviews (AMSTAR-2)

Number and percentage of reviews that had high confidence ratings: 

```{r amstar-high}
#number/% of high confidence
sum(td_amstar$amstar_confidence_rating == "1. High") 
sum(td_amstar$amstar_confidence_rating == "1. High")  / nrow(td_amstar) * 100 

```

Number and percentage of reviews that had moderate confidence ratings: 

```{r amstar-mod}
#number/% of moderate confidence
sum(td_amstar$amstar_confidence_rating == "2. Moderate")
sum(td_amstar$amstar_confidence_rating == "2. Moderate")  / nrow(td_amstar) * 100 

```

Number and percentage of reviews that had low confidence ratings: 

```{r amstar-low}
#number/% of low confidence
sum(td_amstar$amstar_confidence_rating == "3. Low")
sum(td_amstar$amstar_confidence_rating == "3. Low")  / nrow(td_amstar) * 100 

```

Number and percentage of reviews that had critically low confidence ratings: 

```{r amstar-critical-low}
#number/% of critically low confidence
sum(td_amstar$amstar_confidence_rating == "4. Critically Low")
sum(td_amstar$amstar_confidence_rating == "4. Critically Low")  / nrow(td_amstar) * 100 

```

Calculate most common critical weaknesses in AMSTAR ratings among reviews: 

```{r amstar-critical-domains}
#select AMSTAR ratings
amstar_ratings <- td_amstar %>% 
  select(review_author_year, ends_with("rating"))

#change column names to match domain number
names(amstar_ratings) <- c("review_author_year", "1", "2", "3", "4", "5", "6", "7",
                          "8", "9", "10", "11", "12", "13", "14", "15", "16", "amstar_confidence_rating")

#filter for critical domains
amstar_crit <- amstar_ratings %>% 
  select(review_author_year, `2`, `4`, `7`, `9`, `11`, `13`, `15`) %>% 
  pivot_longer(cols = c("2", "4", "7", "9", "11", "13", "15"))

#calculate frequency for "No"s per critical domains
amstar_crit_mode <- amstar_crit %>% 
  group_by(name) %>% 
  summarize(n = sum(value == "No"),
            percent = sum(value == "No") / nrow(amstar_ratings) * 100) %>% 
  arrange(desc(n))
amstar_crit_mode

```

Calculate most common non-critical weaknesses in AMSTAR ratings among reviews: 

```{r amstar-non-crit}
#filter for non-critical domains
amstar_noncrit <- amstar_ratings %>% 
  select(review_author_year, `1`, `3`, `5`, `6`, `8`, `10`, `12`, `14`, `16`) %>% 
  pivot_longer(cols = c("1", "3", "5", "6", "8", "10", "12", "14", "16"))

#calculate frequency for "No"s per non-critical domains
amstar_noncrit_mode <- amstar_noncrit %>% 
  group_by(name) %>% 
  summarize(n = sum(value == "No"),
            percent = sum(value == "No") / nrow(amstar_ratings) * 100) %>% 
  arrange(desc(n))
amstar_noncrit_mode

```

#### Risk of Bias in Included Systematic Reviews (ROBIS) 

Number and percentage of reviews with low risk of bias:

```{r robis-low}
#number/% of low risk
sum(td_robis$robis_overall_rating == "2. Low")
sum(td_robis$robis_overall_rating == "2. Low")  / nrow(td_robis) * 100 

```

Number and percentage of reviews with unclear risk of bias:

```{r robis-unclear}
#number/% of unclear risk
sum(td_robis$robis_overall_rating == "3. Unclear") 
sum(td_robis$robis_overall_rating == "3. Unclear")  / nrow(td_robis) * 100 

```

Number and percentage of reviews with high risk of bias:

```{r robis-high}
#number/% of high risk
sum(td_robis$robis_overall_rating == "1. High") 
sum(td_robis$robis_overall_rating == "1. High")  / nrow(td_robis) * 100 

```

Calculate the most common concerns about risk of bias among reviews:

```{r robis-common-concerns}
#select ratings, transform to long format, calculate percent with high risk
robis_concerns <- td_robis %>% 
  select(review_author_year, ends_with("decision"), robis_overall_a, 
         robis_overall_b, robis_overall_c) %>% 
  pivot_longer(cols = 2:8) %>% 
  group_by(name) %>% 
  summarize(n_decision = sum(value == "1. High"),
            per_decision = sum(value == "1. High") / nrow(td_robis) * 100,
            n_overall = sum(value == "4. No"),
            per_overall = sum(value == "4. No") / nrow(td_robis) * 100) %>% 
  arrange(desc(n_decision))
robis_concerns

```

### Characteristics of Included Primary Studies 

This section includes code to reproduce the characteristics of included primary studies narrative results section.

Range and median for year of publication of primary studies: 

```{r ps-char-year}
#range and median for publication year
range(td_study$study_publication_year)
median(td_study$study_publication_year)

```

Range and median for primary study start and end dates: 

```{r ps-char-startyear}
#extract year from date variables
study_dates <- td_study %>% 
  mutate(start_year = as.numeric(str_extract(study_start_date, "[0-9]{4}")),
         end_year = as.numeric(str_extract(study_end_date, "[0-9]{4}")))

#range/median of start years
range(study_dates$start_year, na.rm = TRUE)
median(study_dates$start_year, na.rm = TRUE)
```

```{r ps-char-endyear}
#range and median of end years
range(study_dates$end_year, na.rm = TRUE)
median(study_dates$end_year, na.rm = TRUE)

```

#### Study design

Number and percentage of intervention and comparison groups per study:

```{r ps-design-groups}
#count number of groups within studies
count_num_groups <- td_study %>% 
  group_by(study_groups) %>% 
  summarize(n = n(),
            percent = n/nrow(td_study)*100)
count_num_groups

```

Number and percentage of studies with individual randomized trials:

```{r design-iRCT}
#number/% of individual randomized trials 
sum(td_study$research_design == "1. Randomized trial" & td_study$assignment_level == "1. Individual")
sum(td_study$research_design == "1. Randomized trial" & td_study$assignment_level == "1. Individual") / nrow(td_study) * 100 

```

Number and percent of studies with cluster randomized trials:

```{r design-cRCT}
#number/% of cluster randomized trials
sum(td_study$research_design == "1. Randomized trial" & td_study$assignment_level == "2. Cluster") 
sum(td_study$research_design == "1. Randomized trial" & td_study$assignment_level == "2. Cluster") / nrow(td_study) * 100 

```

Number and percentage of studies with quasi-experimental design:

```{r design-nonRCT}
#number/% of QEDs
sum(td_study$research_design == "4. QED - Regression adjustment")
sum(td_study$research_design == "4. QED - Regression adjustment") / nrow(td_study) * 100 

```

Within cluster RCTs, number and percentage of studies that clustered by classrooms: 

```{r design-cluster-classroom}
#filter for cluster randomized trials
cluster_df <- td_study %>% 
  filter(research_design == "1. Randomized trial" & assignment_level == "2. Cluster")

#of cluster trials, number/% of classroom cluster type
sum(cluster_df$cluster_type == "1. Classroom") 
sum(cluster_df$cluster_type == "1. Classroom") / nrow(cluster_df) * 100 

```

Within cluster RCTs, number and percentage of studies that clustered by schools

```{r design-cluster-school}
#of cluster trials, number/% of school cluster type
sum(cluster_df$cluster_type == "2. School") 
sum(cluster_df$cluster_type == "2. School") / nrow(cluster_df) * 100 

```

Within cluster RCTs, number and percentage of studies that clustered by districts:

```{r design-cluster-district}
#No districts in data
summary(as.factor(cluster_df$cluster_type))

```

Within cluster RCTs, range and median of cluster size: 

```{r design-cluster-size}
#range/median of cluster size
range(cluster_df$cluster_size, na.rm = TRUE) 
median(cluster_df$cluster_size, na.rm = TRUE)

```

Number and percentage of studies that reported a PRISMA flow diagram: 

```{r design-prisma}
#of all studies, number/% with flow diagram
sum(td_study$consort_flow_diagram == "Yes")
sum(td_study$consort_flow_diagram == "Yes") / nrow(td_study) * 100 

```

Number and percentage of studies that reported a registration number: 

```{r design-registration}
#of all studies, number/% with registration number
sum(td_study$study_registration != "-999") 
sum(td_study$study_registration != "-999") / nrow(td_study) * 100 

```

Number and percentage of studies that reported a data availability statement: 

```{r design-availability}
#of all studies, number/% with availability statement
sum(td_study$availability_statement != "-999") 
sum(td_study$availability_statement != "-999") / nrow(td_study) * 100 

```

#### Participant characteristics

Number students across all primary studies:

```{r participants-n}
#number of students
sum(td_study$number_participants) 

```

Range and median of number of students across all primary studies:

```{r participants-n2}
#median and range of students
median(td_study$number_participants) 
range(td_study$number_participants) 

```

Number of classrooms included across primary studies: 

```{r participants-classrooms}
#number of classrooms
sum(td_study$number_classrooms, na.rm = TRUE) 

```

Range and median of number of classrooms included in primary studies: 

```{r participants-classrooms2}
#median and range of classrooms
range(td_study$number_classrooms, na.rm = TRUE) 
median(td_study$number_classrooms, na.rm = TRUE)

```

Number of schools included across primary studies: 

```{r participants-schools}
#number of schools
sum(td_study$number_schools, na.rm = TRUE) 

```

Range and median of number of schools included in primary studies: 

```{r participants-schools2}
#median and range of schools
median(td_study$number_schools, na.rm = TRUE)
range(td_study$number_schools, na.rm = TRUE) 

```

Range and median of average student age

```{r participants-age}
#range and median of mean student age
range(td_study$average_age, na.rm = TRUE) 
median(td_study$average_age, na.rm = TRUE)

```

Number and percent of studies that took place in elementary or primary schools:

```{r participants-elem-schl}
#create count variables per school level since some responses contain more than one school type
count_school_level <- td_study %>% 
  mutate(elem_count = str_count(school_level, "Elementary") + str_count(school_level, "Primary"),
         mid_count = str_count(school_level, "Middle"),
         high_count = str_count(school_level, "High") + str_count(school_level, "Secondary")) 

#number/% studies in elementary or primary school
sum(count_school_level$elem_count) 
sum(count_school_level$elem_count) / nrow(td_study) * 100 

```

Number and percent of studies that took place in middle schools:

```{r participants-mid-schl}
#number/% studies in middle school
sum(count_school_level$mid_count) 
sum(count_school_level$mid_count) / nrow(td_study) * 100 

```

Number and percent of studies that took place in high or secondary schools:

```{r participants-high-schl}
#number/% studies in high or secondary school
sum(count_school_level$high_count) 
sum(count_school_level$high_count) / nrow(td_study) * 100 

```

Calculate most common grade levels among studies:

```{r participants-grd-level}
#create flag variables per grade level since some responses contain more than one school type
count_grade_level <- td_study %>% 
  mutate(first_flag = str_count(grade_level, "1"), 
         second_flag = str_count(grade_level, "2"), 
         third_flag = str_count(grade_level, "3"), 
         fourth_flag = str_count(grade_level, "4"), 
         fifth_flag = str_count(grade_level, "5"), 
         sixth_flag = str_count(grade_level, "6"), 
         seventh_flag = str_count(grade_level, "7"), 
         eighth_flag = str_count(grade_level, "8"), 
         ninth_flag = str_count(grade_level, "9"), 
         tenth_flag = str_count(grade_level, "10"),
         eleventh_flag = str_count(grade_level, "11"),
         twelveth_flag = str_count(grade_level, "12")) %>% 
  select(primary_study_id, grade_level, ends_with("flag")) %>% 
  pivot_longer(cols = first_flag:twelveth_flag,
               names_to = "grade") %>% 
  group_by(grade) %>% 
  summarize(n = sum(value),
            percent = n/nrow(td_study)*100) %>% 
  arrange(desc(n))
head(count_grade_level)

```

Range and median of percentage of female students among primary studies: 

```{r participants-female}
#range and median of % female
range(td_study$percent_female, na.rm = TRUE) 
median(td_study$percent_female, na.rm = TRUE) * 100

```

Number of studies conducted in the United States

```{r participants-USA}
#number of studies in U.S.
sum(td_study$country == "United States") 

```

Of studies conducted in the U.S., range and median of percentage of white students:

```{r participants-US-white}
#create subset with only studies conducted in U.S.
US_study <- td_study %>% 
  filter(country == "United States")

#of US studies, range and median of % white
range(US_study$percent_white * 100, na.rm = TRUE) 
median(US_study$percent_white, na.rm = TRUE) * 100 

```

Of studies conducted in the U.S., range and median of percentage of ELL students:

```{r participants-US-ELL}
#of US studies, range and median of % ELL
range(US_study$percent_ELL, na.rm = TRUE) 

```

Of studies conducted in the U.S., range and median of percentage of students receiving free or reduced price lunch:

```{r participants-US-FRPL}
#of US studies, range and median of % FRPL
range(US_study$percent_FRPL, na.rm = TRUE) #only 2 values = 29% - 46%
median(US_study$percent_FRPL, na.rm = TRUE)

```

#### Setting characteristics

Most common countries where primary studies took place: 

```{r setting-countries}
#count most common countries
count_country <- td_study %>% 
  group_by(country) %>% 
  summarize(n = n(),
            percent = n/nrow(td_study)*100) %>% 
  arrange(desc(n))
head(count_country)

```

Most common states where primary studies conducted in the U.S. took place: 

```{r setting-states}
#of US countries, count most common states
count_states <- US_study %>% 
  group_by(state) %>% 
  summarize(n = n(),
            percent = n/nrow(US_study)*100) %>% 
  arrange(desc(n))
head(count_states)

```

Number and percentage of studies that provided information about area type: 

```{r setting-location-type}
#number of studies providing location type (urbanicity)
sum(td_study$urbanicity != "4. Cannot tell")
sum(td_study$urbanicity != "4. Cannot tell") / nrow(td_study) * 100 

```

Of studies reporting area type, number and percentage of studies that took place in each area type: 

```{r setting-location}
#count location type by creating new count variable since more than one are listed per cell
count_urbanicity <- td_study %>% 
  filter(urbanicity != "4. Cannot tell") %>% 
  mutate(rural_count = str_count(urbanicity, "Rural"),
         suburban_count = str_count(urbanicity, "Suburban"), 
         urban_count = str_count(urbanicity, "Urban")) %>% 
  select(primary_study_id, urbanicity, ends_with("count")) %>% 
  pivot_longer(cols = rural_count:urban_count,
               names_to = "area_type") %>% 
  group_by(area_type) %>% 
  summarize(n = sum(value),
            percent = sum(value)/sum(td_study$urbanicity != "4. Cannot tell")*100) %>% 
  arrange(desc(n))
count_urbanicity

```

Number and percentage of primary studies that reported type of school: 

```{r setting-schl-type}
#number of studies reporting school type
sum(td_study$school_type != "Cannot Tell")
sum(td_study$school_type != "Cannot Tell") / nrow(td_study) * 100 

```

Of studies reporting school type, number and percentage of studies with each school type: 

```{r setting-counrties}
#count school type by creating new variables since more than one per cell
count_schooltype <- td_study %>% 
  filter(school_type != "Cannot Tell") %>% 
  mutate(public_count  = str_count(school_type, "Public"),
         private_count = str_count(school_type, "Private"), 
         charter_count = str_count(school_type, "Charter"),
         parochial_count = str_count(school_type, "Parochial")) %>% 
  select(primary_study_id, school_type, ends_with("count")) %>% 
  pivot_longer(cols = public_count:parochial_count,
               names_to = "schooltype") %>% 
  group_by(schooltype) %>% 
  summarize(n = sum(value),
            percent = sum(value)/sum(td_study$school_type != "Cannot Tell")*100) %>% 
  arrange(desc(n))
count_schooltype
  
```

#### Experimental Interventions

Number of experimental interventions among primary studies: 

```{r intervention-n}
#filter for experimental interventions 
grp_int <- td_group %>% 
  filter(group_type == "1. Intervention")

#number of experimental interventions (group type)
nrow(grp_int)

```

Number and percentage of each intervention format: 

```{r intervention-format}
#number/% of format (intervention_format)
count_format <- grp_int %>% 
  group_by(intervention_format) %>% 
  summarize(n = n(),
            percent = n/nrow(grp_int)*100)
count_format

```

Range and median of intervention duration (in weeks): 

```{r intervention-duration}
#range/median of duration (intervention_weeks)
range(grp_int$intervention_weeks, na.rm = TRUE) 
median(grp_int$intervention_weeks, na.rm = TRUE) 

```

Range and median of number of intervention sessions delivered: 

```{r intervention-session}
#range/median of # of sessions (intervention_sessions)
range(grp_int$intervention_sessions, na.rm = TRUE) 
median(grp_int$intervention_sessions, na.rm = TRUE)

```

Range and median of intervention session length (in minutes): 

```{r intervention-intensity}
#range/median of session length (intervention_intensity)
range(grp_int$intervention_intensity, na.rm = TRUE)
median(grp_int$intervention_intensity, na.rm = TRUE)

```

Number of interventions with reported information on frequency of intervention delivery: 

```{r intervention-frequency}
#number of interventions with frequency info (intervention_frequency)
sum(grp_int$intervention_frequency != "-999") 

```

Of interventions reporting frequency of delivery, number and percentage of interventions with each frequency: 

```{r intervention-freq-count}
#Of those reporting frequency, number/% of frequency
grp_int %>% 
  filter(intervention_frequency != "-999") %>% 
  group_by(intervention_frequency) %>% 
  summarize(n = n(),
            percent = n/sum(grp_int$intervention_frequency != "-999")*100)

```

Number of interventions with reported information about intervention provider: 

```{r intervention-provider}
#number of interventions with provider info (intervention_provider)
sum(grp_int$intervention_provider != "8. Cannot Tell")

```

Of interventions reporting provider, number and percentage of interventions with each provider type: 

```{r intervention-provider-count}
#Of those reporting provider, number/% by provider, create count variable since more than one response per cell
count_intprovider <- grp_int %>% 
  filter(intervention_provider != "8. Cannot Tell") %>% 
  mutate(teacher_count  = str_count(intervention_provider, "Teacher"),
         counselor_count = str_count(intervention_provider, "Guidance Counselor"), 
         bhpersonnel_count = str_count(intervention_provider, "Behavioral Health Personnel"),
         researcher_count = str_count(intervention_provider, "Researcher"),
         schlpersonnel_count = str_count(intervention_provider, "Other School Personnel"),
         self_count = str_count(intervention_provider, "Self-Administered"),
         other_count = str_count(intervention_provider, "7. Other")) %>% 
  select(primary_study_id, intervention_provider, ends_with("count")) %>% 
  pivot_longer(cols = teacher_count:other_count,
               names_to = "provider") %>% 
  group_by(provider) %>% 
  summarize(n = sum(value),
            percent = sum(value)/sum(grp_int$intervention_provider != "8. Cannot Tell") *100) %>% 
  arrange(desc(n))
count_intprovider

```

Number of interventions with reported information on recipient type: 

```{r intervention-recipients}
#number of interventions with recipient info (intervention_recipients)
sum(grp_int$intervention_recipients != "7. Cannot Tell") 

```

Of interventions reporting recipient type, number and percentage of interventions with each recipient type: 

```{r intervention-recipients-count}
#Of those reporting recipient, number/% by recipient type, create count variable since more than one response per cell
count_intrecip <- grp_int %>% 
  filter(intervention_provider != "7. Cannot Tell") %>% 
  mutate(student_count  = str_count(intervention_recipients, "Student"),
         peers_count = str_count(intervention_recipients, "Peers"), 
         teacher_count = str_count(intervention_recipients, "Teacher"),
         staff_count = str_count(intervention_recipients, "Staff"),
         family_count = str_count(intervention_recipients, "Family"),
         community_count = str_count(intervention_recipients, "Community")) %>% 
  select(primary_study_id, intervention_recipients, ends_with("count")) %>% 
  pivot_longer(cols = student_count:community_count,
               names_to = "recipients") %>% 
  group_by(recipients) %>% 
  summarize(n = sum(value),
            percent = sum(value)/sum(grp_int$intervention_recipients != "7. Cannot Tell") *100) %>% 
  arrange(desc(n))
count_intrecip

```

Number of interventions with reported information on where the intervention was delivered: 

```{r intervention-location}
#number of interventions with location info (intervention_location)
sum(grp_int$intervention_location != "7. Cannot tell")

```

Of interventions reporting location, number and percentage of interventions with each location type: 

```{r intervention-location-count}
#Of those reporting location, number/% by location type, create count variable since more than one response per cell
count_intloc <- grp_int %>% 
  filter(intervention_location != "7. Cannot tell") %>% 
  mutate(inschl_count  = str_count(intervention_location, "During School Time"),
         outschl_count = str_count(intervention_location, "Out-of-School Time"), 
         home_count = str_count(intervention_location, "Home"),
         community_count = str_count(intervention_location, "Community"),
         residential_count = str_count(intervention_location, "Residential"),
         other_count = str_count(intervention_location, "Other")) %>% 
  select(primary_study_id, intervention_location, ends_with("count")) %>% 
  pivot_longer(cols = inschl_count:other_count,
               names_to = "location") %>% 
  group_by(location) %>% 
  summarize(n = sum(value),
            percent = sum(value)/sum(grp_int$intervention_location != "7. Cannot tell") *100) %>% 
  arrange(desc(n))
count_intloc

```

Number of interventions with reported information on mode of delivery: 

```{r intervention-delivery}
#number of interventions with delivery mode (intervention_mode)
sum(grp_int$intervention_mode != "-999") 

```

Of interventions reporting delivery, number and percentage of interventions with each delivery mode type: 

```{r intervention-delivery-count}
#Of those reporting delivery mode, number/% by delivery mode, create count variable since more than one response per cell
count_intmode <- grp_int %>% 
  filter(intervention_mode != "-999") %>% 
  mutate(inperson_count  = str_count(intervention_mode, "In-Person"),
         internet_count = str_count(intervention_mode, "Internet"), 
         phone_count = str_count(intervention_mode, "Phone")) %>% 
  select(primary_study_id, intervention_mode, ends_with("count")) %>% 
  pivot_longer(cols = inperson_count:phone_count,
               names_to = "mode") %>% 
  group_by(mode) %>% 
  summarize(n = sum(value),
            percent = sum(value)/sum(grp_int$intervention_mode != "-999") *100) %>% 
  arrange(desc(n))
count_intmode

```

Number and percentage of studies with reported information on implementation monitoring: 

```{r intervention-implementation}
#create new variable that will flag if a study had any group that reported any implementation info 
group_study_flag <- grp_int %>% 
  group_by(primary_study_id) %>% 
  mutate(monitor_flag = case_when(any(intervention_monitoring == "Yes") ~ "Yes",
                                  TRUE ~ intervention_monitoring),
         problem_flag = case_when(any(intervention_problems == "Yes") ~ "Yes",
                                  TRUE ~ intervention_problems)) %>% 
  ungroup() %>% 
  select(primary_study_id, ends_with("flag")) %>% 
  distinct(primary_study_id, .keep_all = TRUE)

#number/% reporting implementation monitoring 
sum(group_study_flag$monitor_flag == "Yes") 
sum(group_study_flag$monitor_flag == "Yes") / nrow(group_study_flag) * 100 

```

Number and percentage of studies that reported any implementation problems:

```{r intervention-session}
#number/% reporting implementation problems
sum(group_study_flag$problem_flag == "Yes") 
sum(group_study_flag$problem_flag == "Yes") / nrow(group_study_flag) * 100 

```

#### Comparison Interventions

Number of comparison interventions among primary studies: 

```{r comparison-n}
#filter for comparison interventions 
grp_comp <- td_group %>% 
  filter(group_type == "2. Comparison")

#number of comparison interventions 
nrow(grp_comp)

```

Number and percentage of each type of comparison group type: 

```{r comparison-type}
#number/% of comparison group type (comparison_type)
count_comptype <- grp_comp %>% 
  group_by(comparison_type) %>% 
  summarize(n = n(),
            percent = n/nrow(grp_comp)*100)
count_comptype

```

#### Risk of bias

**Individually-Randomized Trials (iROB 2)** 

Number of individually-randomized trials:

```{r irob-n}
#number of iRCT studies
nrow(irob_df) 

```

Among individual RCTs, number and percentage of each overall risk of bias rating:

```{r irob-ratings}
#number/% for overall rating
count_irobtot <- irob_df %>% 
  group_by(iROB_overall_rating) %>% 
  summarize(n = n(), 
            percent = n/nrow(irob_df)*100)
count_irobtot

```

Among individual RCTs, most common concerns regarding risk of bias ratings (number and percentage of high ratings):

```{r irob-concerns}
#calculate most common domains with High ratings
count_irobratings <- irob_df %>% 
  pivot_longer(cols = iROB_domain1_judgment:iROB_domain5_judgment) %>% 
  group_by(name) %>% 
  summarize(n = sum(value == "1. High"),
            percent = sum(value == "1. High") / nrow(irob_df) * 100) %>% 
  arrange(desc(n))
count_irobratings

```

**Cluster-Randomized Trials (cROB 2)**

Number of cluster-randomized trials:

```{r crob-n}
#number of cRCT studies
nrow(crob_df)

```

Among cluster RCTs, number and percentage of each overall risk of bias rating:

```{r crob-ratings}
#number/% for overall rating
count_crobtot <- crob_df %>% 
  group_by(cROB_overall_rating) %>% 
  summarize(n = n(), 
            percent = n/nrow(crob_df)*100)
count_crobtot

```

Among cluster RCTs, most common concerns regarding risk of bias ratings (number and percentage of high ratings):

```{r crob-concerns}
#calculate most common domains with High ratings
count_crobratings <- crob_df %>% 
  pivot_longer(cols = cROB_domain1a_judgment:cROB_domain5_judgment) %>% 
  group_by(name) %>% 
  summarize(n = sum(value == "1. High"),
            percent = sum(value == "1. High") / nrow(crob_df) * 100) %>% 
  arrange(desc(n))
count_crobratings

```

**Non-Randomized Trials (ROBINS-I)**

Number of non-randomized trials:

```{r robinsi-n}
#number of QED studies
nrow(robins_df)

```

Among QEDs, number and percentage of each overall risk of bias rating:

```{r robinsi-ratings}
#number/% for overall rating
count_robinstot <- robins_df %>% 
  group_by(robins_overall_rating) %>% 
  summarize(n = n(), 
            percent = n/nrow(robins_df)*100)
count_robinstot

```

Among QEDs, most common concerns regarding risk of bias ratings (number and percentage of serious or critical ratings):

```{r robinsi-concerns}
#calculate most common domains with Serious or Critical ratings
count_robinsratings <- robins_df %>% 
  pivot_longer(cols = robins_domain1_judgment:robins_domain7_judgment) %>% 
  group_by(name) %>% 
  summarize(n = sum(value == "3. Serious") + sum(value == "4. Critical"),
            percent = (sum(value == "3. Serious") + sum(value == "4. Critical")) / nrow(robins_df) * 100) %>% 
  arrange(desc(n))
count_robinsratings

```

## Meta-Analysis

### KQ1: What is the effect of school based depression prevention interventions on depression diagnosis? 

Number and percentage of studies reporting effect size data on depression diagnosis: 

```{r k1-descriptives-es}
#number/% of studies with effect size data
length(unique(depression_diagnosis$study))
length(unique(depression_diagnosis$study)) / sum(ps_elig_td$decision == "Include") * 100 

```

Number and percentage of participants across studies reporting effect size data:

```{r k1-descriptives-n}
#get list of studies that included depression diagnosis effect size
depdiag_studs <- depression_diagnosis %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_depdiag <- td_study %>% 
  filter(study_author_year %in% depdiag_studs)

#sum and percent of participants
sum(sl_depdiag$number_participants) 
sum(sl_depdiag$number_participants) / sum(td_study$number_participants) * 100 

```

Most common measures for depression diagnosis: 

```{r k1-descriptives-measures}
#calculate most common measures
depdiag_measure <- depression_diagnosis %>% 
  mutate_outcome_measure() %>% 
  distinct(study, agg_outcome_meas, .keep_all = TRUE) %>% 
  group_by(agg_outcome_meas) %>% 
  summarize(n = n(),
            percent = n/length(unique(depression_diagnosis$study))*100) %>% 
  arrange(desc(n))
depdiag_measure

```

Range and median for length of follow-up for outcome measurement: 

```{r k1-descriptives-followup}
#range/median of length of follow up
range(depression_diagnosis$outcome_timepoint) 
median(depression_diagnosis$outcome_timepoint) 

```

Range and median for number of effect estimates reported in studies: 

```{r k1-descriptives-studyeffect}
#calculate number of effect estimates per study
depdiag_effects <- depression_diagnosis %>% 
  group_by(study) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n)) %>% 
  ungroup()

#range/median of number of effects per study
range(depdiag_effects$n) #1-6
median(depdiag_effects$n) #2

```

Total number of effect sizes reported for depression diagnosis

```{r k1-descriptives-neffect}
#total effect sizes
nrow(depression_diagnosis) #33

```

Calculate effect sizes and conduct random effects robust variance meta-analysis:

```{r MA-dd}
#calculate effect size
dd_escalc <- escalc(measure="RR", ai = intervention_harmful_ess, bi = intervention_beneficial_ess, ci = comparison_harmful_ess, di = comparison_beneficial_ess, data = depression_diagnosis)

#conduct RVE meta-analysis
dd_intercept <- robu(formula = yi ~ 1, data = dd_escalc, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
dd_intercept

```

Calculate risk ratio estimate from log results: 

```{r MA-dd-RR}
#exponentiate estimate to transform to risk ratio
depdiag_RRestimate <- exp(dd_intercept$reg_table$b.r)
depdiag_RRlowerci <- exp(dd_intercept$reg_table$CI.L)
depdiag_RRupperci <- exp(dd_intercept$reg_table$CI.U)
paste0("risk ratio = ", round(depdiag_RRestimate, 2), ", 95% CI [", round(depdiag_RRlowerci, 2), " to ", round(depdiag_RRupperci, 2), "]")

```

Calculate percentage decrease in risk of depression diagnosis:

```{r MA-dd-percent}
# RR <1, calculate decrease in risk
percent_decrease <- (1-depdiag_RRestimate) * 100
percent_decrease

```

Calculate prediction interval:

```{r MA-dd-PI}
#extract log model results
depdiag_estimate <- dd_intercept$reg_table$b.r
depdiag_tausq <- as.numeric(dd_intercept$mod_info$tau.sq)
depdiag_se <- dd_intercept$reg_table$SE
depdiag_k <- dd_intercept$N

#determine critical t-value
depdiag_criticalt <- qt(p = .05/2, df = depdiag_k - 2, lower.tail = FALSE)

#calculate prediction interval and exponentiate
depdiag_exp_pilower <- exp(depdiag_estimate - (depdiag_criticalt*sqrt(depdiag_tausq + (depdiag_se^2))))
depdiag_exp_piupper <- exp(depdiag_estimate + (depdiag_criticalt*sqrt(depdiag_tausq + (depdiag_se^2))))
paste0("95% PI [", round(depdiag_exp_pilower, 2), " to ", round(depdiag_exp_piupper, 2), "]")

```

Calculate cumulative distribution function for t-distribution:

```{r MA-dd-CDF}
#calculate t value for CDF calculation
depdiag_t <- (0 - depdiag_estimate) / sqrt(depdiag_tausq + (depdiag_se^2))

#calculate CDF
dd_cdf_test <- pt(depdiag_t, depdiag_k - 1)
dd_cdf_test * 100

```

### KQ2: What is the effect of school based depression prevention interventions on subsyndromal and depressive symptoms? 

#### Subsyndromal Depression

Number and percentage of studies reporting effect size data on subsyndromal depression:

```{r subsyndromal-descriptives-es}
#number/% of studies with effect sizes
length(unique(subsyndromal_depression$study))
length(unique(subsyndromal_depression$study)) / sum(ps_elig_td$decision == "Include") * 100 #

```

Number and percentage of participants across studies with effect size data: 

```{r subsyndromal-descriptives-participants}
#get list of studies that included subsyndromal depression effect size
subsynd_studs <- subsyndromal_depression %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_subsynd <- td_study %>% 
  filter(study_author_year %in% subsynd_studs)

#sum and percent
sum(sl_subsynd$number_participants) 
sum(sl_subsynd$number_participants) / sum(td_study$number_participants) * 100 

```

Most commonly used measures for subsyndromal depression:

```{r subsyndromal-descriptives-measures}
#most common measures
subsynd_measure <- subsyndromal_depression %>% 
  mutate_outcome_measure() %>% 
  distinct(study, agg_outcome_meas, .keep_all = TRUE) %>% 
  group_by(agg_outcome_meas) %>% 
  summarize(n = n(),
            percent = n/length(unique(subsyndromal_depression$study))*100) %>% 
  arrange(desc(n))
subsynd_measure

```

Range and median for length of follow up:

```{r subsyndromal-descriptives-followup}
#range/median of length of follow up
range(subsyndromal_depression$outcome_timepoint) 
median(subsyndromal_depression$outcome_timepoint) 

```

Range and median of number of effect estimates reported per study:

```{r subsyndromal-descriptives-studyeffect}
#calculate number of effect estimates per study
subsynd_effects <- subsyndromal_depression %>% 
  group_by(study) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n)) %>% 
  ungroup()

#range/median of number of effects per study
range(subsynd_effects$n) 
median(subsynd_effects$n) 

```

Total number of effect sizes reported for subsyndromal depression:

```{r subsyndromal-descriptives-n}
#total effect sizes
nrow(subsyndromal_depression)

```

Meta-Analysis Results: The degrees of freedom are below the threshold to use robust variance estimation to conduct meta-analysis on subsyndromal depression. 

#### Depression Symptoms

Number and percentage of studies reporting effect size data on depression symptoms: 

```{r ds-descriptives-es}
#number/% of studies with effect sizes
length(unique(depression_symptoms$study)) 
length(unique(depression_symptoms$study)) / sum(ps_elig_td$decision == "Include") * 100 

```

Number and percentage of participants across studies with effect size data: 

```{r ds-descriptives-participants}
#get list of studies that included depression symptoms effect size
depsymp_studs <- depression_symptoms %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_depsymp <- td_study %>% 
  filter(study_author_year %in% depsymp_studs | primary_study_id == 1029) #specify possel 2004 due to accent in one file

#sum and percent
sum(sl_depsymp$number_participants) 
sum(sl_depsymp$number_participants) / sum(td_study$number_participants) * 100 

```

Most commonly used measures for depression symptoms: 

```{r ds-descriptives-measures}
#most common measures
depsymp_measure <- depression_symptoms %>% 
  mutate_outcome_measure() %>% 
  distinct(study, agg_outcome_meas, .keep_all = TRUE) %>% 
  group_by(agg_outcome_meas) %>% 
  summarize(n = n(),
            percent = n/length(unique(depression_symptoms$study))*100) %>% 
  arrange(desc(n))
depsymp_measure

```

Range and median for length of follow-up: 

```{r ds-descriptives-followup}
#range/median of length of follow up
range(depression_symptoms$outcome_timepoint) 
median(depression_symptoms$outcome_timepoint) 

```

Range and median of number of effect estimates reported per study: 

```{r ds-descriptives-studyeffects}
#calculate number of effect estimates per study
depsymp_effects <- depression_symptoms %>% 
  group_by(study) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n)) %>% 
  ungroup()

#range/median of number of effects per study
range(depsymp_effects$n)
median(depsymp_effects$n)

```

Total number of effect sizes reported for depression symptoms: 

```{r ds-descriptives-n}
#total effect sizes
nrow(depression_symptoms) 
```

Conduct random effects robust variance meta-analysis: 

```{r MA-ds-RVE}
#conduct RVE
ds_intercept <- robu(formula = yi ~ 1, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
ds_intercept 

```

Calculate prediction interval: 

```{r MA-ds-PI}
#extract values from meta-analysis
depsymp_estimate <- ds_intercept$reg_table$b.r
depsymp_tausq <- as.numeric(ds_intercept$mod_info$tau.sq)
depsymp_se <- ds_intercept$reg_table$SE
depsymp_k <- ds_intercept$N 

#determine critical t-value
depsymp_criticalt <- qt(p = .05/2, df = depsymp_k - 2, lower.tail = FALSE)

#calculate prediction interval
depsymp_pilower <- depsymp_estimate - (depsymp_criticalt *sqrt(depsymp_tausq + (depsymp_se^2)))
depsymp_piupper <- depsymp_estimate + (depsymp_criticalt *sqrt(depsymp_tausq + (depsymp_se^2)))
paste(round(depsymp_pilower, 2), round(depsymp_piupper, 2))

```

*Calculate cumulative distribution function for t-distribution:*

```{r MA-ds-CDF}
#calculate t value for CDF calculation
depsymp_t <- (0 - depsymp_estimate) / sqrt(depsymp_tausq + (depsymp_se^2))

#calculate CDF
ds_cdf_test <- pt(depsymp_t, depsymp_k - 1)
ds_cdf_test * 100

```

### KQ3: What is the effect of school-based depression prevention interventions on non-depression outcomes related to student well-being and educational achievement?

#### Anxiety Symptoms

Number and percentage of studies reporting effect size data on anxiety symptoms: 

```{r anxiety-descriptives-es}
#number/% of studies with effect sizes
length(unique(anxiety_symptoms$study)) 
length(unique(anxiety_symptoms$study)) / sum(ps_elig_td$decision == "Include") * 100 

```

Number and percentage of participants across studies with effect size data: 

```{r anxiety-descriptives-participants}
#get list of studies that included anxiety symptoms effect size
anxiety_studs <- anxiety_symptoms %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_anxiety <- td_study %>% 
  filter(study_author_year %in% anxiety_studs)

#sum and percent
sum(sl_anxiety$number_participants)
sum(sl_anxiety$number_participants) / sum(td_study$number_participants) * 100

```

Most commonly used measures for anxiety symptoms:

```{r anxiety-descriptives-measures}
#most common measures
anxiety_measure <- anxiety_symptoms %>% 
  mutate_outcome_measure() %>% 
  distinct(study, agg_outcome_meas, .keep_all = TRUE) %>% 
  group_by(agg_outcome_meas) %>% 
  summarize(n = n(),
            percent = n/length(unique(anxiety_symptoms$study))*100) %>% 
  arrange(desc(n))
anxiety_measure

```

Range and median for length of follow-up:

```{r anxiety-descriptives-followup}
#range/median of length of follow up
range(anxiety_symptoms$outcome_timepoint) 
median(anxiety_symptoms$outcome_timepoint) 

```

Range and median of number of effect estimates reported per study:

```{r anxiety-descriptives-studyeffects}
#calculate number of effect estimates per study
anxiety_effects <- anxiety_symptoms %>% 
  group_by(study) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n)) %>% 
  ungroup()

##range/median of number of effects per study
range(anxiety_effects$n) 
median(anxiety_effects$n)

```

Total number of effect sizes reported for anxiety:

```{r anxiety-descriptives-n}
#total effect sizes
nrow(anxiety_symptoms) 
```

calculate effect sizes and conduct random effects robust variance meta-analysis:

```{r MA-anxiety}
#calculate effect sizes
as_escalc <- escalc(measure="SMD", m1i = followup_intervention_mean, sd1i = followup_intervention_sd, n1i = followup_intervention_n_ess, m2i = followup_comparison_mean, sd2i = followup_comparison_sd, n2i = followup_comparison_n_ess, data = anxiety_symptoms)

#conduct RVE for anxiety
as_intercept <- robu(formula = yi ~ 1, data = as_escalc, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
as_intercept

```

Calculate prediction interval:

```{r MA-anxiety-PI}
#extract values from meta-analysis
anx_estimate <- as_intercept$reg_table$b.r
anx_se <- as_intercept$reg_table$SE
anx_tausq <- as.numeric(as_intercept$mod_info$tau.sq)
anx_k <- as_intercept$N 

#determine critical t-value
anx_criticalt <- qt(p = .05/2, df = anx_k - 2, lower.tail = FALSE)

#calculate prediction interval
anx_pilower <- anx_estimate - (anx_criticalt*sqrt(anx_tausq + (anx_se^2)))
anx_piupper <- anx_estimate + (anx_criticalt*sqrt(anx_tausq + (anx_se^2)))
paste(round(anx_pilower, 2), round(anx_piupper, 2))

```

*Calculate cumulative distribution function for t-distribution:*

```{r MA-ax-CDF}
#calculate t value for CDF calculation
anx_t <- (0 - anx_estimate) / sqrt(anx_tausq + (anx_se^2))

#calculate CDF
ax_cdf_test <- pt(anx_t, anx_k - 1)
ax_cdf_test * 100

```

#### Educational Achievement

Number and percentage of studies reporting effect size data on educational achievement:

```{r ea-descriptives-es}
#number/% of studies with effect sizes
length(unique(edu_achievement$study)) 
length(unique(edu_achievement$study)) / sum(ps_elig_td$decision == "Include") * 100 

```

Number and percentage of participants across studies with effect size data: 

```{r ea-descriptives-participants}
#get list of studies that included effect size
eduach_studs <- edu_achievement %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_eduach <- td_study %>% 
  filter(study_author_year %in% eduach_studs)

#sum and percent
sum(sl_eduach$number_participants) 
sum(sl_eduach$number_participants) / sum(td_study$number_participants) * 100 

```

Meta-Analysis Results: The degrees of freedom are below the threshold to use robust variance estimation to conduct meta-analysis on educational achievement. 

#### Self-Harm

Number and percentage of studies reporting effect size data on self-harm:

```{r sh-descriptives-es}
#number/% of studies with effect sizes 
length(unique(self_harm$study)) 
length(unique(self_harm$study)) / sum(ps_elig_td$decision == "Include") * 100 

```

Number and percentage of participants across studies with effect size data:

```{r sh-descriptives-participants}
#get list of studies that included effect size
selfharm_studs <- self_harm %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_selfharm <- td_study %>% 
  filter(study_author_year %in% selfharm_studs)

#sum and percent
sum(sl_selfharm$number_participants) 
sum(sl_selfharm$number_participants) / sum(td_study$number_participants) * 100 
```

Meta-Analysis Results: The degrees of freedom are below the threshold to use robust variance estimation to conduct meta-analysis on self-harm. 

#### Stress

Number and percentage of studies reporting effect size data on stress:

```{r stress-descriptives-es}
#number/% of studies with effect sizes
length(unique(stress$study))
length(unique(stress$study)) / sum(ps_elig_td$decision == "Include") * 100

```

Number and percentage of participants across studies with effect size data:

```{r stress-descriptives-participants}
#get list of studies that included effect size
stress_studs <- stress %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_stress <- td_study %>% 
  filter(study_author_year %in% stress_studs)

#sum and percent
sum(sl_stress$number_participants) 
sum(sl_stress$number_participants) / sum(td_study$number_participants) * 100 

```

Meta-Analysis Results: The degrees of freedom are below the threshold to use robust variance estimation to conduct meta-analysis on stress. 

#### Substance-Use

Number and percentage of studies reporting effect size data on substance-use:

```{r su-descriptives-es}
#number/% of studies with effect sizes
length(unique(substance_use$study))
length(unique(substance_use$study)) / sum(ps_elig_td$decision == "Include") * 100

```

Number and percentage of participants across studies reporting effect size data:

```{r su-descriptives-participants}
#get list of studies that included effect size
subuse_studs <- substance_use %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_subuse <- td_study %>% 
  filter(study_author_year %in% subuse_studs)

#sum and percent
sum(sl_subuse$number_participants) #5030
sum(sl_subuse$number_participants) / sum(td_study$number_participants) * 100 #10.53%

```

Meta-Analysis Results: The degrees of freedom are below the threshold to use robust variance estimation to conduct meta-analysis on substance-use 

#### Suicidal Ideation

Number and percentage of studies reporting effect size data on suicidal ideation:

```{r si-descriptives-es}
#number/% of studies with effect sizes
length(unique(suicidal_ideation$study)) #1
length(unique(suicidal_ideation$study)) / sum(ps_elig_td$decision == "Include") * 100 #1.49%

```

Number and percentage of participants across studies reporting effect size data:

```{r si-descriptives-participants}
#get list of studies that included effect size
suicide_studs <- suicidal_ideation %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_suicide <- td_study %>% 
  filter(study_author_year %in% suicide_studs)

#sum and percent
sum(sl_suicide$number_participants) #540
sum(sl_suicide$number_participants) / sum(td_study$number_participants) * 100 #1.13%
```

Meta-Analysis Results: The degrees of freedom are below the threshold to use robust variance estimation to conduct meta-analysis on suicidal ideation. 

#### Well-being

Number and percentage of studies reporting effect size data on well-being: 

```{r wb-descriptives-es}
#number/% of studies with effect sizes
length(unique(well_being$study)) 
length(unique(well_being$study)) / sum(ps_elig_td$decision == "Include") * 100 

```

Number and percentage of participants across studies reporting effect size data:

```{r wb-descriptives-participants}
#get list of studies that included effect size
wellbeing_studs <- well_being %>% 
  distinct(study) %>% 
  pull(study)

#filter study level data for only those that have effect sizes
sl_wellbeing <- td_study %>% 
  filter(study_author_year %in% wellbeing_studs)

#sum and percent
sum(sl_wellbeing$number_participants)
sum(sl_wellbeing$number_participants) / sum(td_study$number_participants) * 100 

```

Most commonly used measures for well-being:

```{r wb-descriptives-measures}
#most common measures for well-being
wellbeing_measure <- well_being %>% 
  distinct(study, outcome_measure, .keep_all = TRUE) %>% 
  group_by(outcome_measure) %>% 
  summarize(n = n(),
            percent = n/length(unique(well_being$study))*100) %>% 
  arrange(desc(n))
wellbeing_measure

```

Meta-Analysis Results: The degrees of freedom are below the threshold to use robust variance estimation to conduct meta-analysis on well-being 

### KQ4: Do effects vary by methodological, demographic, and intervention characteristics?

Meta-regression results examining heterogeneity in effect estimates for depression symptoms due to: 

Type of assignment to interventions:

```{r MR-KQ4-assignment}
#meta-regression for assignment to interventions
rct_metaregression <- robu(formula = yi ~ RCT, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
rct_metaregression

```

Risk of bias:

```{r MR-KQ4-rob}
#meta-regression for risk of bias
rob_metaregression <- robu(formula = yi ~ high_rob, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
rob_metaregression

```

Baseline depression:

```{r MR-KQ4-bd}
#meta-regression for baseline depression
bd_metaregression <- robu(formula = yi ~ baseline_depression, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
bd_metaregression

```

School level:

```{r MR-KQ4-schllevel}
#meta-regression for school level
sl_metaregression <- robu(formula = yi ~ secondary_school, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
sl_metaregression

```

School type:

```{r MR-KQ4-schltype}
#meta-regression for school type
public_metaregression <- robu(formula = yi ~ public_school, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
public_metaregression

```

Country:

```{r MR-KQ4-country}
#meta-regression for country
country_metaregression <- robu(formula = yi ~ united_states, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
country_metaregression

```

Level of prevention:

```{r MR-KQ4-prevention}
#meta-regression for level of prevention
prevention_metaregression <- robu(formula = yi ~ primary_prevention, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
prevention_metaregression

```

Comparator type:

```{r MR-KQ4-comptype}
#meta-regression for comparator type
comparator_metaregression <- robu(formula = yi ~ tau_comparator, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
comparator_metaregression

```

Publication year:

```{r MR-KQ4-year}
#meta-regression for publication year
year_metaregression <- robu(formula = yi ~ publication_year, data = depression_symptoms, studynum = study, var.eff.size = vi, rho = .8, small = TRUE)
year_metaregression

```

## Tables

### Table 1. Descriptive characteristics per each included systematic review

Select information from review level descriptives that will be presented in table 1:

```{r table1-perreview}
#select info we for table1
t1_info <- td_review %>% 
  select(review_id, review_author_year, databases_searched, search_date)

```

Calculate the number of included and eligible studies per review:

```{r numstud-perreview}
#transform to long to calculate # of included/eligible studies per review
cm_long <- td_cm %>% 
  select(-`Current Review`) %>% 
  pivot_longer(cols = `Ahlen 2015`:`Zhang 2023`,
               names_to = "review_author_year") 

#count number of included studies per review
numinc_perreview <- cm_long %>% 
  group_by(review_author_year) %>% 
  summarize(n_included = sum(value == "1 - Yes", na.rm = TRUE)) %>% 
  ungroup()

#count number of eligible studies per review
numelig_perreview <- cm_long %>% 
  filter(study %in% inc_ps) %>% 
  group_by(review_author_year) %>% 
  summarize(n_eligible = sum(value == "1 - Yes", na.rm = TRUE)) %>% 
  ungroup()

```

Merge together all above information to get all table 1 data and format it for table 1:

```{r t1-info-merge, warning = FALSE}
#merge and format values
t1 <- left_join(t1_info, numinc_perreview) %>% 
  left_join(numelig_perreview) %>% 
  mutate(search_date_format = ifelse(nchar(search_date) == 10, format(ymd(search_date), "%B %d, %Y"), search_date)) %>% 
  mutate(search_date_format = ifelse(nchar(search_date) == 7, format(ym(search_date), "%B %Y"), search_date_format)) %>% 
  mutate_all(~ replace(., . == -999, "Not Reported")) %>% 
  select(review_author_year, databases_searched, search_date_format, n_included, n_eligible) %>% 
  arrange(str_to_lower(review_author_year))

```

Create table 1:

```{r t1-format}
#create gt table and format
table1_formatted <- t1 %>% 
  gt() %>% 
  cols_align(columns = c("n_included", "n_eligible"), align = "center") %>% 
  tab_style(style = cell_text(align = "left"), locations = cells_column_labels(columns = c("n_included", "n_eligible"))) %>%
  cols_width(review_author_year ~ px(125), databases_searched ~ px(275), search_date_format ~ px(150), starts_with("n") ~ px(75)) %>% 
  cols_label(review_author_year = "Review", 
            databases_searched = "Databases Searched",
            search_date_format = "Search Date",
            n_included = "Included Studies",
            n_eligible = "Eligible Studies") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
  tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.font.names = "Times New Roman")

print(table1_formatted)

```

Save table 1 to `outputs/tables`` project folder: 

```{r t1-save}
#save as word doc
#gtsave(table1_formatted, filename = "table1_word.docx", device = "word", landscape = TRUE) #landscape doesn't work

#save as pdf
#gtsave(table1_formatted, filename = "table1.pdf") 

#save as html with larger column widths
table1_html <- table1_formatted %>% 
  cols_width(review_author_year ~ px(175), databases_searched ~ px(700), search_date_format ~ px(150), starts_with("n") ~ px(75))

gtsave(table1_html, filename = "table_1.html", path = here("outputs", "tables"))

```

### Table 2. AMSTAR-2 Ratings per Question

Select AMSTAR ratings and format to present in table 2:

```{r amstar-table}
#re-format ratings to report in table 2
t2 <- amstar_ratings %>% 
  mutate(review_author_year = as.factor(review_author_year)) %>% 
  mutate_if(is.character, ~case_when(. == "1. High" ~ "H",
                                     . == "2. Moderate" ~ "M",
                                     . == "3. Low" ~ "L",
                                     . == "4. Critically Low" ~ "CL",
                                     . == "Yes" ~ "Y",
                                     . == "Partial yes" ~ "PY",
                                     . == "No" ~ "N",
                                     TRUE ~ .)) %>% 
  arrange(str_to_lower(review_author_year))

```

Create table 2 and format:

```{r t2-format}
#create gt table and format
t2_formatted <- t2 %>% 
  gt() %>% 
  cols_label(review_author_year = "Review", 
            amstar_confidence_rating = "Overall") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
   tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.border.bottom.color = "white",
              table.font.names = "Times New Roman") %>% 
  cols_width(review_author_year ~ px(175),
             amstar_confidence_rating ~ px(75),
             everything() ~ px(35)) %>% 
  tab_style(style = cell_text(align = "center"), locations = cells_column_labels(columns = everything())) %>% 
  tab_style(style = cell_text(align = "left"), locations = cells_column_labels(columns = "review_author_year")) %>% 
  tab_style(style = cell_text(align = "center"), locations = cells_body(columns = everything())) %>% 
  tab_style(style = cell_text(align = "left"), locations = cells_body(columns = "review_author_year")) %>% 
  tab_footnote(footnote = "N = No; PY = Partial Yes; Y = Yes; CL = Critically Low; L = Low; M = Moderate; H = High") %>% 
  data_color(columns = 2:18,
             colors = scales::col_factor(palette = c("#ab1d1a", "#8ace7e", "#e03531", "#ffda66", "#e03531", "#b2dfa8", "#8ace7e"),
                                         domain = c("CL", "H", "L", "M", "N", "PY", "Y")))
             
          
print(t2_formatted)

```

Save table 2 to `outputs/tables`` project folder: 

```{r save-t2}
#save as HTML
gtsave(t2_formatted, filename = "table_2.html", path = here("outputs", "tables"))

#save as word doc
#gtsave(t2_formatted, filename = "table2_word.docx")

```

### Table 3. Risk of Bias in Included Systematic Reviews (ROBIS)

Format rankings for reporting in table: 

```{r robis-table}
#remove leading numbers, select variables
t3 <- td_robis %>% 
    mutate_if(is.character, ~case_when(. == "1. High" ~ "High",
                                     . == "2. Low" ~ "Low",
                                     . == "3. Unclear" ~ "Unclear",
                                     . == "1. Yes" ~ "Yes",
                                     . == "2. Probably Yes" ~ "Probably Yes",
                                     . == "3. Probably No" ~ "Probably No",
                                     . == "4. No" ~ "No",
                                     . == "5. No information" ~ "No Information",
                                     TRUE ~ .)) %>% 
  select(review_author_year, ends_with("decision"), robis_overall_a, robis_overall_b, robis_overall_c, robis_overall_rating) %>% 
  arrange(str_to_lower(review_author_year))

```

Create table 3 and format table:

```{r t3-format}
#create gt table
t3_formatted <- t3 %>% 
  gt() %>% 
  cols_label(review_author_year = "Review", 
             robis_1_decision = "Domain 1",
             robis_2_decision = "Domain 2",
             robis_3_decision = "Domain 3",
             robis_4_decision = "Domain 4",
             robis_overall_a = "Interpretation",
             robis_overall_b = "Relevance",
             robis_overall_c = "Spin",
             robis_overall_rating = "Overall") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
   tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.border.bottom.color = "white",
              table.font.names = "Times New Roman") %>% 
   cols_width(review_author_year ~ px(150),
              robis_overall_a ~ px(110),
              robis_overall_b ~ px(100),
              robis_overall_c ~ px(100),
              everything() ~ px(100),
              robis_overall_rating ~ px(50)) %>% 
  data_color(columns = 2:9,
             colors = scales::col_factor(palette = c("#e03531", "#8ace7e", "#e03531", "gray60", "#ef9997", "#b2dfa8", "#ffda66", "#8ace7e"),
                                         domain = c("High", "Low", "No", "No Information", "Probably No", "Probably Yes", "Unclear", "Yes")))


print(t3_formatted)

```

Save table 3 to `outputs/tables`` project folder: 

```{r t3-save}
#save as html
gtsave(t3_formatted, filename = "table_3.html", path = here("outputs", "tables"))

#save as word doc
#gtsave(t3_formatted, filename = "table3_word.docx")

```

### Table 4. Characteristics of Included Primary Studies

Select variables for table 4 from the various data sets: 

```{r t4-info}
#select study level variables for table 4
t4_info <- td_study %>% 
  select(primary_study_id, study_author_year, country, number_participants, number_classrooms,
         number_schools, school_level, research_design, assignment_level, rob_tool)

#select relevant individual rob data
t4_irob <- study_irob %>% 
  select(primary_study_id, iROB_overall_rating) %>% 
  rename(overall_rob_rating = iROB_overall_rating) 

#select relevant cluster rob data
t4_crob <- study_crob %>% 
  select(primary_study_id, cROB_overall_rating) %>% 
  rename(overall_rob_rating = cROB_overall_rating)

#select relevant QED rob data
t4_robins <- study_robins %>% 
  select(primary_study_id, robins_overall_rating) %>% 
  rename(overall_rob_rating = robins_overall_rating) 

#bind together all rob data for primary studies
t4_allrob <- rbind(t4_irob, t4_crob, t4_robins)

#merge rob info with t4_info and format data for table
t4 <- t4_info %>% 
  left_join(t4_allrob) %>% 
  select(-rob_tool, -primary_study_id) %>% 
  mutate_at(vars(school_level, research_design, assignment_level, overall_rob_rating), list(~str_remove(., "^[0-9]+\\. "))) %>% 
  mutate(school_level = str_replace(school_level, ",(...)(.*)", ",\\2")) %>% 
  mutate(school_level = str_replace(school_level, "School", ""),
         design = case_when(research_design == "Randomized trial" & assignment_level == "Individual" ~ "Individual RCT",
                            research_design == "Randomized trial" & assignment_level == "Cluster" ~ "Cluster RCT",
                            research_design == "QED - Regression adjustment" ~ "QED",
                            TRUE ~ research_design)) %>% 
  mutate(school_level = case_when(school_level == "Only Reported Secondary " ~ "Secondary",
                                  school_level == "Only Reported Primary " ~ "Primary",
                                  school_level == "Only Reported Primary , Only Reported Secondary School" ~ "Primary , Secondary",
                                  school_level == "Cannot tell" ~ "NR",
                                  TRUE ~ school_level)) %>% 
  mutate(school_level = str_replace(school_level, "(,.)", "and "),
         number_participants = format(number_participants, big.mark = ",", scientific = FALSE)) %>% 
  mutate(school_level = str_replace(school_level, "School", "")) %>%
  mutate_if(is.numeric, as.character) %>% 
  mutate_all(list(~ifelse(is.na(.), "NR", .))) %>% 
  select(study_author_year:school_level, design, overall_rob_rating)

#select variables needed from group level data
t4_group <- group_level %>% 
  select(primary_study_id, group_number, group_type, gname, ig_group_type,  comparison_type) %>%
  left_join(study_idbyname) %>% 
  mutate_all(list(~ifelse(. == -999, "Not reported", .))) %>% 
  mutate_at(vars(group_type, ig_group_type, comparison_type), list(~str_remove(., "^[0-9]+\\. "))) %>% 
  select(primary_study_id, study_author_year, everything()) %>% 
  arrange(study_author_year) 

#transform intervention names data to merge
t4group_intnames <- t4_group %>% 
  group_by(study_author_year, group_type) %>% 
  summarize(group_names = paste(gname, collapse = "; ")) %>% 
  ungroup() %>% 
  filter(group_type == "Intervention")

#transform comparison types data to merge
t4group_compnames <- t4_group %>% 
  mutate(comparison_type = case_when(comparison_type == "Active" ~ paste("Active:", gname),
                                     TRUE ~ comparison_type)) %>% 
  group_by(study_author_year, group_type) %>% 
  summarize(comp_type = paste(comparison_type, collapse = "; ")) %>% 
  ungroup() %>% 
  filter(group_type == "Comparison")

#merge group names and transform to wide format
t4group_wide <- t4group_intnames %>% 
  left_join(t4group_compnames, by = "study_author_year") %>% 
  rename(Intervention = group_names,
         Comparison = comp_type) %>% 
  select(-starts_with("group")) %>% 
  mutate_all(~ str_replace_all(., "Cannot tell", "NR"))

#merge group level with study level data
t4_full <- left_join(t4, t4group_wide) %>% 
  select(study_author_year:school_level, Intervention, Comparison, design, overall_rob_rating) %>% 
  arrange(str_to_lower(stringi::stri_trans_general(study_author_year, "Latin-ASCII")))

```

Create table 4 and format table:

```{r t4-format}
#create gt table 
t4_formatted <- t4_full %>% 
  gt() %>% 
  cols_label(study_author_year = "Study", 
             country = "Country",
             number_participants = "Students",
             number_classrooms = "Classrooms",
             number_schools = "Schools",
             school_level = "Level",
             design = "Design",
             overall_rob_rating = "Risk of Bias") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
  tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.border.bottom.color = "white",
              table.font.names = "Times New Roman") %>% 
  tab_style(style = cell_text(align = "left"), locations = cells_body(columns = "number_participants")) %>% 
  tab_footnote(footnote = md("**NR = Not reported; TAU: Treatment as usual; RCT = Randomized controlled trial; QED = Quasi-experimental design**"))

print(t4_formatted)

```

Save table 3 to `outputs/tables`` project folder: 

```{r t3-save}
#save as html
gtsave(t4_formatted, filename = "table_4.html", path = here("outputs", "tables"))

```

## Figures

### Figure 1. PRISMA flow diagram reporting

Using Zotero info and reference_level file (for review level), calculate information for prisma & screening/eligibility reporting.

Calculate numbers for PRISMA diagram (review-level):
 * The only value not in our dataset is the number of records identified in the search before duplicate removal. Our last search yielded *5,223* records that were imported into Zotero before duplicate removal. 

```{r prisma, echo = FALSE}
#number of records imported for abstract screening
nrow(td_reference)

#number of records excluded at title/abstract (drops)
#number of full-text references assessed for eligibility (keeps)
summary(td_reference$screening_consensus)

#number of *reviews* assessed for eligibility
review_assessed <- td_screen_review %>% 
  summarize(number_studies = n_distinct(review_id)) %>% 
  pull(number_studies)
review_assessed

#number of *reviews* excluded during full-text eligibility 
sum(td_screen_review$eligibility_consensus == "Not Eligible")

#number of *reviews* excluded per reason
rev_exclude_reason <- td_screen_review %>% 
  filter(eligibility_consensus == "Not Eligible") %>% 
  group_by(exclude_reason) %>% 
  summarize(n = n())
rev_exclude_reason

#number of *reviews* included during full text eligibility 
sum(td_screen_review$eligibility_consensus == "Eligible")

#percentage of eligible reviews out of all full-text *reviews* assessed for eligibility
sum(td_screen_review$eligibility_consensus == "Eligible") / sum(td_screen_review$screening_consensus == "1. Keep") * 100

#percentage of eligible reviews out of all *references* identified
sum(td_screen_review$eligibility_consensus == "Eligible") / nrow(td_reference) * 100

```

Calculate numbers for PRISMA diagram (primary study level):

```{r prisma-ps}
#total primary studies assessed
nrow(ps_elig_td)

#total eligible
sum(ps_elig_td$decision == "Include")
#percentage 
sum(ps_elig_td$decision == "Include") / nrow(ps_elig_td) * 100

#total not eligible (unclear = not eligible)
sum(ps_elig_td$decision == "Exclude" | ps_elig_td$decision == "Unclear")

#reasons for not eligible
#unclear = awaiting classification 
sum(ps_elig_td$decision == "Unclear")

#collapsed reasons
ps_exclude_reasons <- ps_elig_td %>% 
  filter(decision == "Exclude") %>% 
  group_by(reason) %>% 
  summarize(n = n())
ps_exclude_reasons

```

Create reproducible PRISMA diagram:

```{r test-prisma}
#load templates for prisma diagram
template <- getPrisma(studyStatus)
format <- getPrismaFormat(studyStatus)

#edit template 
ourformat <- format %>% 
  filter(prismaLvl != 1) %>% 
  mutate(prismaTxt = case_when(prismaLvl == 2 & nodeType == "Node" ~ "Records identified from search:\n(n = 5,223)", #from zotero
                               prismaLvl == 3 & nodeType == "Node" ~ paste0("Records screened: \n(n = ", 
                                                                            format(nrow(td_reference), big.mark = ","),")"),
                               prismaLvl == 4 & nodeType == "Node" ~ paste0("Reports sought for retrieval: \n(n = ", 
                                                                            sum(td_reference$screening_consensus == "1. Keep"), ")"),
                               prismaLvl == 5 & nodeType == "Node" ~ paste0("Reports assessed for eligibility: \n(n = ", 
                                                                            sum(td_reference$screening_consensus == "1. Keep"), "; k = ", 
                                                                            review_assessed, ")"),
                               prismaLvl == 6 & nodeType == "End" ~ paste0("Reviews included in overview: \n(k = ", 
                                                                           sum(td_screen_review$eligibility_consensus == "Eligible"), "; j = ", 
                                                                           nrow(ps_elig_td), ")"),
                               prismaLvl == 2 & nodeType == "Filter" ~ paste0("Records removed before screening: \n(n = ", 
                                                                              5223-nrow(td_reference), ")"),
                               prismaLvl == 3 & nodeType == "Filter" ~ paste0("Records excluded: \n(n = ", 
                                                                              sum(td_reference$screening_consensus == "2. Drop"), ")"),
                               prismaLvl == 4 & nodeType == "Filter" ~ "Reports not retrieved: \n(n = 0)",
                               prismaLvl == 5 & nodeType == "Filter" ~ paste0("Reviews excluded (k = ", 
                                                                              sum(td_screen_review$eligibility_consensus == "Not Eligible"), "):",
                                                                              "\n Anxiety focus only (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "01. Ineligible due to anxiety focus only")$n, ")",
                                                                              "\n Ineligible population (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "02. Ineligible population (not K-12 students)")$n, ")",
                                                                              "\n Ineligible interventions (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "03. Ineligible interventions (not universal or secondary prevention)")$n, ")",
                                                                              "\n Ineligible comparator (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "04. Ineligible comparator (no comparator)")$n, ")",
                                                                              "\n Ineligible outcomes (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "05. Ineligible outcomes (no depression outcomes)")$n, ")",
                                                                              "\n Ineligible setting (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "07. Ineligible setting (not in school settings)")$n, ")",
                                                                              "\n Not a systematic review (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "08. Ineligible study design (not a systematic review)")$n, ")",
                                                                              "\n Not a meta-analysis (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "09. Ineligible study design (no meta-analysis)")$n, ")",
                                                                              "\n Ineligible publication type (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "10. Ineligible publication type (not a full report)")$n, ")",
                                                                              "\n Other (k = ", 
                                                                              subset(rev_exclude_reason, exclude_reason == "11. Other reason (please specify in notes)")$n, ")"),
                               TRUE ~ prismaTxt)) %>% 
  mutate(nodeType = ifelse(prismaLvl == 6, "Node", nodeType))

  
  
#add new rows to template to include primary study information
newnodes <- data.frame(prismaLvl = c(7, 6), 
                      nodeType = c("End", "Filter"), 
                      prismaTxt = c(paste0("Studies included in overview: \n(j = ", 
                                           sum(ps_elig_td$decision == "Include"), ")"),
                                    paste0("Studies excluded (j = ", 
                                           sum(ps_elig_td$decision == "Exclude" | ps_elig_td$decision == "Unclear"), "):",
                                    "\n Awaiting classification (j = ", 
                                           sum(ps_elig_td$decision == "Unclear"), ")", 
                                    "\n Anxiety focus only (j = ", 
                                           subset(ps_exclude_reasons, reason == "01. Ineligible due to anxiety focus only")$n, ")",
                                    "\n Ineligible population (j = ", 
                                           subset(ps_exclude_reasons, reason == "02. Ineligible population (not K-12 students)")$n, ")",
                                    "\n Ineligible intervention (j = ", 
                                           subset(ps_exclude_reasons, reason == "03. Ineligible interventions (not universal or secondary prevention)")$n, ")",
                                    "\n Ineligible comparator (j = ", 
                                           subset(ps_exclude_reasons, reason == "04. Ineligible comparator (no comparator)")$n, ")",
                                    "\n Ineligible setting (j = ", 
                                           subset(ps_exclude_reasons, reason == "07. Ineligible setting (not in school settings)")$n, ")"
                                    )))

#merge together all nodes for prisma diagram
finalformat <- rbind(ourformat, newnodes) 

#create PRISMA diagram 
f1 <- getPrisma(studyStatus, finalformat)
f1_viz <- grViz(f1)

f1_viz
```

Save figure 1 to `outputs/figures` project folder: 

```{r save-f1}
#save figure 1
htmlwidgets::saveWidget(f1_viz, "temp.html")
webshot("temp.html", here("outputs", "figures", "figure1_prisma.png"))
file.remove("temp.html")

```

### Figure 2. Overlap of included studies across systematic reviews

Create CCA heatmap of overlap of included studies across reviews:

```{r ccaR-f2}
#format citation matrix including our review
cca_inc <- td_cm %>% 
  mutate_at(vars(-study), ~ifelse(. == "1 - Yes", 1, 0)) %>% 
  rename(` Current Review` = `Current Review`)

#create pairwise heatmap with CCA(%), including our review
f2 <- cca_heatmap(cca_inc, decimal_digits = 0, fontsize = 4.5, fontsize_diag = 3) +
  ggplot2::theme(
      plot.caption = ggplot2::element_text(size = 16, margin=ggplot2::margin(30,0,0,0)),
      legend.title = ggplot2::element_text(size = 16, face = "bold", vjust=4),
      legend.text = ggplot2::element_text(size = 16),
      legend.key.size = ggplot2::unit(1.0, "cm"),
      legend.title.align = 0.5,
      legend.text.align = 0.5,
      axis.text.x=ggplot2::element_text(size = 16),
      axis.text.y=ggplot2::element_text(size = 16),
      axis.title=ggplot2::element_blank(),
      axis.ticks=ggplot2::element_blank(),
      axis.line=ggplot2::element_blank(),
      panel.border=ggplot2::element_blank(),
      panel.grid.major.x=ggplot2::element_line(colour = "grey80", linetype = "dashed"))

f2

```

Save figure 2 to `outputs/figures` project folder: 

```{r save-f2}
#set image dimensions and file path to save
png(here("outputs", "figures", "figure2_heatmap.png"), width = 1000, height = 1000)

#show plot
f2

#save png of plot
dev.off()
```

### Figure 3. Overlap of eligible studies across systematic reviews

Filter for studies that met our inclusion criteria and create CCA heatmap of our eligible studies across reviews: 

```{r ccaR-elig-f3}
#format citation matrix of eligible studies, including our review
cca_elig <- td_cm %>% 
  filter(study %in% inc_ps) %>% 
  mutate_at(vars(-study), ~ifelse(. == "1 - Yes", 1, 0))  %>% 
  rename(` Current Review` = `Current Review`)

#create pairwise heatmap with CCA(%)
f3 <- cca_heatmap(cca_elig, decimal_digits = 0, fontsize = 4.5, fontsize_diag = 3.2) +
  ggplot2::theme(
      plot.caption = ggplot2::element_text(size = 16, margin=ggplot2::margin(30,0,0,0)),
      legend.title = ggplot2::element_text(size = 16, face = "bold", vjust=4),
      legend.text = ggplot2::element_text(size = 16),
      legend.key.size = ggplot2::unit(1.0, "cm"),
      legend.title.align = 0.5,
      legend.text.align = 0.5,
      axis.text.x = ggplot2::element_text(size = 16),
      axis.text.y = ggplot2::element_text(size = 16),
      axis.title = ggplot2::element_blank(),
      axis.ticks = ggplot2::element_blank(),
      axis.line = ggplot2::element_blank(),
      panel.border = ggplot2::element_blank(),
      panel.grid.major.x = ggplot2::element_line(colour = "grey80", linetype = "dashed"))

print(f3)

```

Save figure 3 to `outputs/figures` project folder: 

```{r save-f3}
#set image dimensions and file path to save
png(here("outputs", "figures", "figure3_heatmap.png"), width = 1000, height = 1000)

#show plot
f3

#save png of plot
dev.off()
```

### Figure 4. Forest plot for depression diagnosis meta-analysis

Create forest plot for depression diagnosis results: 

```{r f4-forestplot}
#create forest plot
forest.robu(dd_intercept, es.lab = "outcome_measure", study.lab = "study", "Follow-up" = outcome_timepoint, "Intervention" = intervention)

```

Save forest plot as pdf with specified page dimensions: 

```{r f4-forestplot}
#set page dimensions and file path to save
pdf(here("outputs", "figures", "figure4_forestplot.pdf"), width = 20, height = 15)

#forest plot to save
forest.robu(dd_intercept, es.lab = "outcome_measure", study.lab = "study", "Follow-up" = outcome_timepoint, "Intervention" = intervention)

#save pdf of plot
dev.off()

```

## Appendices

### Appendix 1. List of excluded reviews

Create data frame with info Appendix 1. List of excluded reviews at the full-text eligibility stage (excluded review & reason):

```{r list-excl-review}
#using reference level data, extract author/year from citation
fm_ref <- td_reference %>% 
  mutate(author = str_extract(citation, "^\\S+"),
         authornocom = str_replace(author, ",", ""),
         author_full = str_extract(citation, "^([^,(]*)"),
         year = str_extract(citation, "[0-9]{4}"),
         author_year = paste(author_full, year, sep = " "))

#select not eligible studies and columns of info to report in appendix 1
a1_info <- fm_ref %>% 
  filter(eligibility_consensus == "Review Not Eligible" | eligibility_consensus == "Not Eligible") %>% 
  mutate(exclude_reason = str_extract(exclude_reason, "(?<=\\.)\\s+(.*)")) %>% 
  select(author_year, exclude_reason, screening_id, citation) %>% 
  arrange(author_year)

#correct review names that parsed incorrectly from incorrect citation
a1 <- a1_info %>% 
  mutate(author_year = case_when(author_year == " 2006" ~ "\"The Effect of Preventative\" 2006",
                                 author_year == " 2010" ~ "\"Methods to Prevent\" 2010",
                                 author_year == "Abdelfettah Elkchirid PhD 2022" ~ "Elkchirid 2022",
                                 author_year == "Alba‐Elena Martinez‐Santos 2021" ~ "Martinez‐Santos 2021",
                                 author_year == "Anonymous  2022" ~ "Steains 2021",
                                 author_year == "Anonymous  2011" ~ "Teubert 2011",
                                 author_year == "Bevan Jones 2018" ~ "Bevan-Jones 2018",
                                 author_year == "Brown 2018" ~ "Brown 2018a",
                                 author_year == "C Hendricks Brown 2018" ~ "Brown 2018b",
                                 author_year == "Julian Edbrooke‐Childs 2021" ~ "Edbrooke‐Childs 2021",
                                 author_year == "Joelle Yan Xin Chua 2020" ~ "Chua 2020",
                                 author_year == "Josefa González Moller 2021" ~ "Moller 2021",
                                 author_year == "Latefa Ali Dardas 2018" ~ "Dardas 2018",
                                 author_year == "Negreiros de Carvalho 2021" ~ "Carvalho 2021",
                                 author_year == "Soneson Emma 2020" ~ "Soneson 2020",
                                 author_year == "Sun Jae Moon 2020" ~ "Moon 2020",
                                 author_year == "Sylvia Deidre Kauer 2014" ~ "Kauer 2014",
                                 author_year == "Zarakoviti Eleni 2021" ~ "Zarakoviti 2021",
                                 TRUE ~ author_year)) %>% 
  select(author_year, exclude_reason) %>% 
  arrange(str_to_lower(stringi::stri_trans_general(author_year, "Latin-ASCII")))

```

Create table for appendix 1 and format: 

```{r a1-tableformat}
#create gt table and format
a1_formatted <- a1 %>% 
  gt()  %>% 
  cols_label(author_year = "Excluded Review", 
             exclude_reason = "Reason for Exclusion") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
  tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.border.bottom.color = "white",
              table.font.names = "Times New Roman") %>% 
  tab_header(title = md("**<div style='text-align: center;'>Appendix 1</div>**<div style='text-align: center; margin-top:10px; margin-bottom:20px;'>**List of Reviews Excluded at Full-Text Eligibility Assessment**<br></div>")) %>% 
  tab_style(style = list(cell_text(align = "center")),
            locations = cells_title(groups = "title"))

print(a1_formatted)

```

Save appendix 1 to `outputs/appendices`` project folder: 

```{r save-a1}
#save as word
#gtsave(a1_formatted, filename = "appendix1.docx")

#save as html
gtsave(a1_formatted, filename = "appendix_1.html", path = here("outputs", "appendices"))

#save as pdf
#gtsave(a1_formatted, filename = "appendix1_pdf.pdf")
```

### Appendix 2. List of excluded primary studies

Create data frame with info for appendix 2 - list of excluded primary studies (excluded study & reason):

```{r list-excl-study}
#filter for excluded studies and delete leading numbers from reason for reporting in tables
a2 <- ps_elig_td %>% 
  filter(decision == "Exclude" | decision == "Unclear") %>% 
  select(study, reason, rationale, decision) %>% 
  mutate(reason = case_when(decision == "Unclear" ~ "Awaiting classification",
                            reason == "01. Ineligible due to anxiety focus only" ~ 
                                            "Ineligible due to anxiety focus only",
                            reason == "02. Ineligible population (not K-12 students)" ~
                                            "Ineligible population (not K-12 students)",
                            reason == "03. Ineligible interventions (not universal or secondary prevention)" ~
                                            "Ineligible interventions (not universal or secondary prevention)",
                            reason == "04. Ineligible comparator (no comparator)" ~
                                            "Ineligible comparator (no comparator)",
                            reason == "05. Ineligible outcomes (no depression outcomes)" ~
                                            "Ineligible outcomes (no depression outcomes)",
                            reason == "07. Ineligible setting (not in school settings)" ~
                                            "Ineligible setting (not in school settings)",
                            reason == "08. Ineligible study design (not a systematic review)" ~
                                            "Ineligible study design (not a systematic review)",
                            reason == "09. Ineligible study design (no meta-analysis)" ~
                                            "Ineligible study design (no meta-analysis)",
                            reason == "10. Ineligible publication type (not a full report)" ~
                                            "Ineligible publication type (not a full report)",
                            reason == "11. Other reason (please specify in notes)" ~
                                            "Other reason (please specify in notes)",
                                          TRUE ~ reason)) %>% 
  select(study, reason) %>% 
  arrange(str_to_lower(study))

```

Create table for appendix 2 and format: 

```{r a2-formattable}
#create gt table and format
a2_formatted <- a2 %>% 
  gt()  %>% 
  cols_label(study = "Excluded Study", 
             reason = "Reason for Exclusion") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
  tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.border.bottom.color = "white",
              table.font.names = "Times New Roman") %>% 
  tab_header(title = md("**<div style='text-align: center;'>Appendix 2</div>**<div style='text-align: center; margin-top:10px; margin-bottom:20px;'>**List of Studies Excluded at Full-Text Eligibility Assessment**<br></div>")) %>% 
  tab_style(style = list(cell_text(align = "center")),
            locations = cells_title(groups = "title"))

print(a2_formatted)

```

Save appendix 2 to `outputs/appendices`` project folder: 

```{r a2-save}
#save as word
#gtsave(a2_formatted, filename = "appendix2.docx")

#save as html
gtsave(a2_formatted, filename = "appendix_2.html", path = here("outputs", "appendices"))

#save as pdf
#gtsave(a2_formatted, filename = "appendix2_pdf.pdf")
```

### Appendix 3. Primary studies awaiting classification 

Create data frame with info for appendix 3 - list of unclear/awaiting classification reviews and primary studies:
 *No reviews awaiting classification*

```{r a3-unclear-ps}
#filter for studies awaiting classification
ps_unclear <- ps_elig_td %>% 
  filter(decision == "Unclear") 

#rename linking key in primary study references dataframe
ps_ref <- ps_allreferences %>% 
  rename(citation = report) %>% 
  distinct(study, .keep_all = TRUE) #only keep main study reference
  
#join primary study reference info with studies awaiting classification 
a3_info <- left_join(ps_unclear, ps_ref, by = "study")

#collapse reasons 
a3 <- a3_info %>% 
  # mutate(reason = case_when(str_detect(rationale, "Ask authors") ~ "Awaiting response to author query",
  #                           str_detect(rationale, "No document") ~ "Unpublished document",
  #                           str_detect(rationale, "Not in English") ~ "No document in English",
  #                           TRUE ~ rationale)) %>% 
  select(study, rationale, citation)

```

Create table for appendix 3 and format:

```{r a3-formattable}
#create formatted gt table
a3_formatted <- a3 %>% 
  gt()  %>% 
  cols_label(study = "Study", 
             rationale = "Reason",
             citation = "Reference") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
  tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.border.bottom.color = "white",
              table.font.names = "Times New Roman") %>% 
  tab_header(title = md("**<div style='text-align: center;'>Appendix 3</div>**<div style='text-align: center; margin-top:10px; margin-bottom:20px;'>**List of Studies Awaiting Classification**<br></div>")) %>% 
  tab_style(style = list(cell_text(align = "center")),
            locations = cells_title(groups = "title"))

print(a3_formatted)


```

Save appendix 3 to `outputs/appendices`` project folder: 

```{r a3-save}
# #save as word
# gtsave(a3_formatted, filename = "appendix3.docx")

#save as html
gtsave(a3_formatted, filename = "appendix_3.html", path = here("outputs", "appendices"))

# #save as html
# gtsave(a3_formatted, filename = "appendix3_pdf.pdf")
```

### Appendix 4. Descriptive characteristics for each included systematic review 

Select information to display in appendix 4 (descriptive characteristics for each included systematic review) and format data for table:

```{r per-review-descriptives, warning = FALSE}
#select relevant appendix 4 info
a4_info <- td_review %>% 
  left_join(numelig_perreview) %>% 
  left_join(numinc_perreview) %>% 
  mutate(search_date = ifelse(nchar(search_date) == 10, format(ymd(search_date), "%B %d, %Y"), search_date)) %>% 
  mutate(search_date = ifelse(nchar(search_date) == 7, format(ym(search_date), "%B %Y"), search_date)) %>% 
  mutate(across(everything(), ~ifelse(.x == -999, "Not reported", .x)),
         n_included = as.character(n_included),
         n_eligible = as.character(n_eligible)) %>% 
  select(review_author_year, starts_with("review_eligibility"), databases_searched, 
         search_date, n_included, n_eligible, prisma_flow_diagram, review_registration, review_availability_statement) %>% 
  arrange(str_to_lower(review_author_year)) 

#select citation info for eligible reviews
review_citations <- td_reference %>% 
  left_join(review_idbyname) %>% 
  filter(review_author_year %in% inc_rev)

#create variable that combines all references for a review into one cell
review_reports <- review_citations %>% 
  group_by(review_author_year) %>% 
  summarize(all_reports = paste(citation, collapse = " !!! ")) %>% 
  ungroup() %>% 
  mutate(all_reports = str_replace_all(all_reports, "!!! ", "<br><br>"),
         merge_author = stri_trans_general(review_author_year, "Latin-ASCII"),
         merge_author = str_to_lower(merge_author)) %>% 
  select(review_author_year, merge_author, all_reports)

#extract titles from .bib
rev_titles <- review_bib %>% 
    rowwise() %>% 
  mutate(author_unlist = paste(lapply(author, paste, collapse = ","), collapse = ", "),
         author = str_extract(author_unlist, "^[^,]+"),
         author_year = paste(author, year), 
         title = str_replace_all(title, "[{}]", ""),
         title = str_remove(title, "\\.$"),
         merge_author = stri_trans_general(author_year, "Latin-ASCII"),
         merge_author = str_to_lower(merge_author)) %>% 
  select(author_year, merge_author, title) %>% 
  arrange(str_to_lower(author_year))

#merge titles and citations with other a4 info and format eligibility cells
a4 <- a4_info %>% 
  mutate(merge_author = stri_trans_general(review_author_year, "Latin-ASCII"),
         merge_author = str_to_lower(merge_author)) %>% 
  left_join(rev_titles, by = "merge_author") %>% 
  left_join(review_reports, by = "merge_author") %>% 
  mutate_at(vars(starts_with("review_eligibility")), list(~ str_replace_all(., "\\s-\\s(?=[A-Z])", "<br> - "))) %>% 
  mutate_at(vars(starts_with("review_eligibility")), ~ str_replace_all(., "- ([A-Z])", " <li>\\1")) %>% 
  mutate_at(vars(starts_with("review_eligibility")), ~ paste0("<ul>", ., "</ul>")) %>% 
  rename(review_author_year = review_author_year.x) %>% 
  select(review_author_year, title, review_eligibility_participants:review_availability_statement, all_reports)
  
```

Create one long data frame that has all information to present in appendix 4 for each review:

```{r a4-mapdf}
#split data frame into list of data frames
a4_dflist <- map(1:nrow(a4), ~a4[.x, ])

#transfer to long format
df_list_long <- map(a4_dflist, ~ .x %>% 
                      pivot_longer(cols = everything(), 
                                   names_to = "variable", 
                                   values_to = "value") %>% 
                      mutate(variable = case_when(variable == "review_author_year" ~ "Review",
                                                  variable == "title" ~ "Title",
                                                  variable == "review_eligibility_participants" ~ "Participants",
                                                  variable == "review_eligibility_interventions" ~ "Interventions",
                                                  variable == "review_eligibility_comparisons" ~ "Comparisons",
                                                  variable == "review_eligibility_outcomes" ~ "Outcomes",
                                                  variable == "review_eligibility_timing" ~ "Timing",
                                                  variable == "review_eligibility_setting" ~ "Setting",
                                                  variable == "review_eligibility_studies" ~ "Studies",
                                                  variable == "databases_searched" ~ "Databases Searched",
                                                  variable == "search_date" ~ "Search Date",
                                                  variable == "prisma_flow_diagram" ~ "Prisma Diagram", 
                                                  variable == "review_registration" ~ "Registration",
                                                  variable == "review_availability_statement" ~ "Data Availability Statement",
                                                  variable == "n_eligible" ~ "Eligible Studies",
                                                  variable == "n_included" ~ "Included Studies",
                                                  variable == "all_reports" ~ "References",
                                                  TRUE ~ variable)))
  
#combine into one single data frame
combined_a4 <- bind_rows(df_list_long, .id = "source") %>% 
  mutate(source = as.numeric(source))

```

Create list of tables for each review to present in appendix 4: 

```{r a4-maptable, results ='asis'}
#create gt table for each for each review
list_gt <- lapply(split(combined_a4, combined_a4$source), function(x) {
  gt(x) %>% 
    cols_hide("source") %>% 
    cols_label(variable = "",
               value = "") %>% 
    tab_style(style = list(cell_text(weight = "bold")),
            locations = cells_body(columns = "variable")) %>% 
    tab_row_group(rows = 3:9, label = "Eligibility Criteria:") %>% 
    tab_row_group(rows = 1:2, label = "", id = "group1") %>% 
    tab_options(table.font.names = "Times New Roman") %>% 
    tab_style(style = cell_text(weight = "bold"), locations = cells_row_groups()) %>% 
    tab_style(style = cell_text(align = "right"), locations = cells_body(columns = "variable", rows = 3:9)) %>%
    fmt_markdown(columns = everything())
})

#add title
a4_title_html <- '<h2 style="text-align:center;font-family:Times New Roman;font-size:20px;margin-bottom:5px;margin-top:25px;">
  <div>Appendix 4</div>
  <div style="margin-top:10px; margin-bottom:10px;">Characteristics of Included Reviews</div>
</h2>'


#extract HTML code of table
html_code <- list_gt %>% 
  map(as_raw_html) %>% 
  reduce(paste) %>% 
  paste(a4_title_html, ., sep = "\n")

#print in document
htmltools::browsable(htmltools::HTML(html_code))

```

Save appendix 4 to `outputs/appendices`` project folder: 

```{r a4-save}
#save as HMTL
writeLines(html_code, here("outputs", "appendices", "appendix_4.html"))

```

### Appendix 5. Characteristics of Included Primary Studies

Select information to display in appendix 5 (descriptive characteristics for each included primary study) and format data for table: 

```{r a5-info, warning = FALSE}
#select study level info and format for table
a5_info <- td_study %>% 
  mutate_at(vars(school_level, state, urbanicity, research_design, assignment_level, cluster_type), list(~str_remove(., "^[0-9]+\\. "))) %>% 
  mutate(school_level = str_replace(school_level, ",(...)(.*)", ",\\2"),
         urbanicity = str_replace_all(urbanicity, "\\s\\d+\\.", ",")) %>% 
  mutate(school_level = case_when(school_level == "Only Reported Secondary School" ~ "Secondary School",
                                  school_level == "Only Reported Primary School" ~ "Primary School",
                                  school_level == "Only Reported Primary School, Only Reported Secondary School" ~ "Primary School , Secondary School",
                                  school_level == "Cannot tell" ~ "Not reported",
                                  TRUE ~ school_level),
         grade_level = ifelse(grade_level == "Cannot tell", "Not reported", grade_level),
         urbanicity = str_replace_all(urbanicity, "\\s+,", ","),
         urbanicity = str_replace_all(urbanicity, ",,", ","),
         cluster_type = ifelse(assignment_level != "Cluster", "NA", cluster_type),
         cluster_size = ifelse(assignment_level != "Cluster", "NA", cluster_size)) %>% 
  mutate(school_level = str_replace(school_level, "(,.)", " and "),
         percent_mixed = ifelse(percent_mixed == "-999", NA_real_, as.numeric(percent_mixed)),
         percent_other = ifelse(percent_other == "-999", NA_real_, as.numeric(percent_other)),
         state = ifelse(state == "Cannot tell", "Not reported", state),
         research_design = ifelse(research_design == "QED - Regression adjustment", "Quasi-experimental design", research_design)) %>% 
  mutate(study_start_date = ifelse(nchar(study_start_date) == 10, format(ymd(study_start_date), "%B %d, %Y"), study_start_date),
         study_end_date = ifelse(nchar(study_end_date) == 10, format(ymd(study_end_date), "%B %d, %Y"), study_end_date)) %>% 
  mutate(study_start_date = ifelse(nchar(study_start_date) == 7, format(ym(study_start_date), "%B %Y"), study_start_date),
         study_end_date = ifelse(nchar(study_end_date) == 7, format(ym(study_end_date), "%B %Y"), study_end_date)) %>% 
  mutate(number_participants = format(number_participants, big.mark = ",", scientific = FALSE),
         sample_size = case_when(!is.na(number_participants) & !is.na(number_classrooms) & !is.na(number_schools) ~
                                   paste(number_participants, "students,", number_classrooms, "classrooms,", number_schools, "schools"),
                                 !is.na(number_participants) & !is.na(number_classrooms) & is.na(number_schools) ~
                                   paste(number_participants, "students,", number_classrooms, "classrooms"),
                                 !is.na(number_participants) & is.na(number_classrooms) & is.na(number_schools) ~
                                   paste(number_participants, "students"),
                                 !is.na(number_participants) & is.na(number_classrooms) & !is.na(number_schools) ~
                                   paste(number_participants, "students,", number_schools, "schools"),
                                 is.na(number_participants) & !is.na(number_classrooms) & !is.na(number_schools) ~
                                   paste(number_classrooms, "classrooms,", number_schools, "schools"),
                                 is.na(number_participants) & !is.na(number_classrooms) & is.na(number_schools) ~
                                   paste(number_classrooms, "classrooms"),
                                 is.na(number_participants) & is.na(number_classrooms) & !is.na(number_schools) ~
                                   paste(number_schools, "schools")),
         sample_size = str_trim(sample_size, side = "left"),
         grd_schl_level = paste(grade_level, "/", school_level),
         age_mean_sd = paste0(average_age, " (", age_dispersion, ")"),
         percent_female = ifelse(!is.na(percent_female), paste0(percent_female * 100, "%"), "Not reported"),
         percent_ELL = ifelse(!is.na(percent_ELL), paste0(percent_ELL * 100, "%"), "Not reported"),
         percent_FRPL = ifelse(!is.na(percent_FRPL), paste0(percent_FRPL * 100, "%"), "Not reported"),
         percent_race_ethnicity = case_when(is.na(percent_white) & is.na(percent_black) & is.na(percent_aian) &
                                            is.na(percent_asian) & is.na(percent_nhpi) & is.na(percent_latinx) & 
                                            is.na(percent_mixed) & is.na(percent_other) ~ "Not reported",
                                            TRUE ~ paste0(percent_aian * 100, "% AIAN, ", percent_asian * 100, "% Asian, ",
                                                          percent_black * 100, "% Black, ", percent_latinx * 100, "% Latinx, ",
                                                          percent_nhpi * 100, "% NHPI, ", percent_white * 100, "% White, ", 
                                                          percent_mixed * 100, "% Mixed, ", percent_other * 100, "% Other")),
         country_state = case_when(state != "Non-US Study" ~ paste0(country, " (", state, ")"),
                                   TRUE ~ country)) %>%
  mutate(age_mean_sd = case_when(age_mean_sd == "NA (-999)" ~ "Not reported",
                                 str_detect(age_mean_sd, "-999") ~ paste(average_age),
                                 TRUE ~ age_mean_sd),
         percent_race_ethnicity = str_replace_all(percent_race_ethnicity, c("NA% AIAN, " = "", "NA% Asian, " = "", "NA% Black, " = "",
                                                                            "NA% Latinx, " = "", "NA% NHPI, " = "", "NA% White, " = "",
                                                                            "NA% Mixed, " = "", "NA% Other" = ""))) %>% 
  mutate(percent_race_ethnicity = gsub(", $", "", percent_race_ethnicity)) %>% 
  mutate(across(everything(), ~ifelse(.x == -999 | .x == "Cannot tell" | .x == "Cannot Tell" | is.na(.x), "Not reported", .x))) %>%
  select(study_author_year, study_start_date, study_end_date, recruitment_approach, 
         eligibility_criteria, research_design, assignment_level, cluster_type, cluster_size, study_groups,
         sample_size, grd_schl_level, age_mean_sd, percent_female, percent_race_ethnicity, percent_ELL, percent_FRPL,
         country_state, urbanicity, school_type, consort_flow_diagram, study_registration, availability_statement)

#merge with group/intervention names created for table 4
a5_groups <- left_join(a5_info, t4group_wide)

#merge with outcome data and combine outcomes for each study
a5_outcome <- outcome_level %>% 
  left_join(study_idbyname) %>%
  mutate(outcome_domain = str_remove(outcome_domain, "^[0-9]+\\. ")) %>% 
  distinct(study_author_year, outcome_domain, .keep_all = TRUE) %>% 
  group_by(study_author_year) %>% 
  summarize(outcome_list = paste(outcome_domain, collapse = ", ")) %>% 
  ungroup() %>% 
  mutate(outcome_list = sapply(lapply(str_split(outcome_list, ", "), sort), paste, collapse = ", ")) %>% 
  select(study_author_year, outcome_list) %>% 
  right_join(a5_groups) %>% 
  arrange(str_to_lower(study_author_year))

#merge with rob data created in table 4
a5_rob <- t4_allrob %>% 
  left_join(study_idbyname) %>% 
  right_join(a5_outcome) %>% 
  mutate(overall_rob_rating = str_remove(overall_rob_rating, "^[0-9]+\\. "),
         overall_rob_rating = str_replace(overall_rob_rating, "-999", "Not reported")) %>% 
  select(study_author_year, study_start_date, study_end_date, recruitment_approach, 
         eligibility_criteria, research_design, assignment_level, cluster_type, cluster_size, study_groups,
         sample_size, grd_schl_level, age_mean_sd, percent_female, percent_race_ethnicity, percent_ELL, percent_FRPL,
         country_state, urbanicity, school_type, Intervention, Comparison, outcome_list, overall_rob_rating,
         consort_flow_diagram, study_registration, availability_statement)

#combine all references for a primary study in a single variable, separated by a semicolon
ps_citations <- ps_allreferences %>% 
  rename(citation = report) %>% 
  filter(study %in% inc_ps)

#create a variable that combines all references for a study into one cell
study_reports <- ps_citations %>% 
  group_by(study) %>% 
  summarize(all_reports = paste(citation, collapse = " ; ")) %>% 
  ungroup() %>% 
  mutate(all_reports = str_replace_all(all_reports, "; ", "<br><br>")) %>% 
  rename(study_author_year = study)

#extract titles and study names from Zotero .bib
ps_titles <- bib_ps_df %>% 
    rowwise() %>% 
  mutate(author_unlist = paste(lapply(author, paste, collapse = ","), collapse = ", "),
         author = str_extract(author_unlist, "^[^,]+"),
         author_year = paste(author, year), 
         title = str_replace_all(title, "[{}]", ""),
         title = str_remove(title, "\\.$"),
         merge_author = stri_trans_general(author_year, "Latin-ASCII"),
         merge_author = str_to_lower(merge_author)) %>% 
  arrange(str_to_lower(author_year))

#merge titles with full citation
study_ref_info <- study_reports %>% 
  mutate(author_year = str_replace(study_author_year, "(\\d{4}).*", "\\1"),
         merge_author = stri_trans_general(author_year, "Latin-ASCII"),
         merge_author = str_to_lower(merge_author)) %>% 
  select(-author_year) %>% 
  left_join(ps_titles) %>% 
  select(title, all_reports, merge_author)

#merge all info for appendix 5 together
a5 <- a5_rob %>% 
  mutate(author_year = str_replace(study_author_year, "(\\d{4}).*", "\\1"),
         merge_author = stri_trans_general(author_year, "Latin-ASCII"),
         merge_author = str_to_lower(merge_author)) %>% 
  left_join(study_ref_info, by = "merge_author", multiple = "all") %>% 
  distinct(study_author_year, .keep_all = TRUE) %>% 
  select(study_author_year, title, study_start_date, study_end_date, recruitment_approach, 
         eligibility_criteria, research_design, assignment_level, cluster_type, cluster_size, study_groups,
         sample_size, grd_schl_level, age_mean_sd, percent_female, percent_race_ethnicity, percent_ELL, percent_FRPL,
         country_state, urbanicity, school_type, Intervention, Comparison, outcome_list, overall_rob_rating,
         consort_flow_diagram, study_registration, availability_statement, all_reports) %>% 
  mutate_if(is.numeric, as.character) %>% 
  arrange(str_to_lower(stringi::stri_trans_general(study_author_year, "Latin-ASCII")))

```

Create one long data frame that has all information to present in appendix 5 for each study:

```{r a5-longlist}
#transfer dataframe into list per df
a5_dflist <- map(1:nrow(a5), ~a5[.x, ])

##transfer to long format
a5_long <- map(a5_dflist, ~ .x %>% 
                      pivot_longer(cols = everything(), 
                                   names_to = "variable", 
                                   values_to = "value") %>% 
                      mutate(variable = case_when(variable == "study_author_year" ~ "Study", 
                                                  variable == "title" ~ "Title",
                                                  variable == "study_start_date" ~ "Start Date",
                                                  variable == "study_end_date" ~ "End Date",
                                                  variable == "recruitment_approach" ~ "Recruitment Approach",
                                                  variable == "eligibility_criteria" ~ "Eligibility Criteria",
                                                  variable == "research_design" ~ "Research Design",
                                                  variable == "assignment_level" ~ "Assignment Level",
                                                  variable == "cluster_type" ~ "Cluster Type",
                                                  variable == "cluster_size" ~ "Average Cluster Size",
                                                  variable == "study_groups" ~ "Trial Arms",
                                                  variable == "sample_size" ~ "Sample Size",
                                                  variable == "grd_schl_level" ~ "Grade/School Level",
                                                  variable == "age_mean_sd" ~ "Age",
                                                  variable == "percent_female" ~ "Percent Female",
                                                  variable == "percent_race_ethnicity" ~ "Percent Racce/Ethnicity",
                                                  variable == "percent_ELL" ~ "Percent ELL",
                                                  variable == "percent_FRPL" ~ "Percent FRPL",
                                                  variable == "country_state" ~ "Country (State)",
                                                  variable == "urbanicity" ~ "Geographic Area",
                                                  variable == "school_type" ~ "School Type",
                                                  variable == "Intervention" ~ "Active Intervention",
                                                  variable == "Comparison" ~ "Comparison Group",
                                                  variable == "outcome_list" ~ "Outcomes",
                                                  variable == "overall_rob_rating" ~ "Risk of Bias",
                                                  variable == "consort_flow_diagram" ~ "Flow Diagram",
                                                  variable == "study_registration" ~ "Registration", 
                                                  variable == "availability_statement" ~ "Data/Code Availability",
                                                  variable == "all_reports" ~ "References",
                                                  TRUE ~ variable)))

#combine into one single dataframe
combined_a5 <- bind_rows(a5_long, .id = "source") %>% 
  mutate(source = as.numeric(source))

```

Create list of tables for each study to present in appendix 5: 

```{r a5-gtlist}
a5_list_gt <- lapply(split(combined_a5, combined_a5$source), function(x) {
  gt(x) %>% 
    cols_hide("source") %>% 
    cols_label(variable = "",
               value = "") %>% 
    cols_width(variable ~ px(175)) %>% 
    tab_style(style = list(cell_text(weight = "bold")),
            locations = cells_body(columns = "variable")) %>% 
    tab_style(style = list(css("text-indent" = "10px")),
              locations = cells_body(columns = "variable", 
                                     rows = c(9, 10))) %>% 
    tab_options(table.font.names = "Times New Roman") %>% 
    fmt_markdown(columns = everything())
})

#add title
a5_title_html <- '<h2 style="text-align:center;font-family:Times New Roman;font-size:20px;margin-bottom:5px;margin-top:25px;">
  <div>Appendix 5</div>
  <div style="margin-top:10px; margin-bottom:10px;">Characteristics of Included Studies</div>
</h2>'

#extract HTML table
html_code_a5 <- a5_list_gt %>% 
  map(as_raw_html) %>% 
  reduce(paste) %>% 
  paste(a5_title_html, ., sep = "\n")

#print in document
htmltools::browsable(htmltools::HTML(html_code_a5))


```

Save appendix 5 to `outputs/appendices`` project folder: 

```{r a5-save}
#save as HMTL
writeLines(html_code_a5, here("outputs", "appendices", "appendix_5.html"))

```


```{r exportRDS}
#Export gt tables and appendices without titles as RDS object to print in technical report

#Combine all gt tables into a list
tables_list <- list(table1 = table1_formatted,
                    table2 = t2_formatted,
                    table3 = t3_formatted,
                    table4 = t4_formatted,
                    appendix1 = a1_formatted %>% tab_header(title = NULL, subtitle = NULL),
                    appendix2 = a2_formatted %>% tab_header(title = NULL, subtitle = NULL),
                    appendix3 = a3_formatted %>% tab_header(title = NULL, subtitle = NULL),
                    appendix4 = combined_a4,
                    appendix5 = combined_a5)

#Save as RDS object to data directory
saveRDS(tables_list, file = "data/tables_list.rds")

```
