---
title: "Analysis Script for JCCP Submission"
author: "Shaina Trevino"
date: "2024-01-24"
output: html_document
---

```{r renv, include=FALSE}
# # Create reproducible environment (DO NOT RUN)
# # Initialize repo (rev version 1.1.3)
# renv::init(project = "publications/2024_JCCP")
# # Install and load pacman package
# if (!require("pacman")) install.packages("pacman")
# # # Install and load required packages
# pacman::p_load(rmarkdown, devtools, here, readxl, janitor, tidyverse, openxlsx, robumeta, metafor, lubridate, gt, webshot2, DiagrammeR, prismadiagramR, stringi, htmltools, bib2df) 
# pacman::p_load_gh("thdiakon/ccaR", "mcguinlu/robvis") #from github
# # Create snapshot of packages for reproducible environment
# renv::snapshot()


```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Install renv for reproducible environment
if (!requireNamespace("renv", quietly = TRUE)) install.packages("renv")

# Load environment
renv::load("publications/2024_JCCP")

# Restore any missing packages
renv::restore("publications/2024_JCCP")

```

```{r libraries}
# Load required packages directly (since restore installs them)
library(rmarkdown)
library(devtools)
library(here)
library(readxl)
library(janitor)
library(tidyverse)
library(openxlsx)
library(lubridate)
library(gt)
library(webshot2)
library(stringi)
library(bib2df)
library(ccaR)


# Set file path for data importing
cwd <- here::here("publications", "2024_JCCP", "data")

```

## Overview

This document produces all the results reported in our publication in Journal of Consulting and Clinical Psychology (JCCP; citation below). The first two sections are importing and data cleaning code followed by code to reproduce our results. Code is presented in the order in which results are presented in the report starting with narrative results, followed by tables, figures, and appendices. Data for this publication were collected in FileMaker initially and additional data collection was completed in DistillerSR. Some files were constructed in excel (e.g., citation matrix).

Grant, S., Schweer-Collins, M., Day, E., Trevino, S. D., Steinka-Fry, K., & Tanner-Smith, E. E. (2024). Effectiveness of school-based depression prevention interventions: An overview of systematic reviews with meta-analyses on depression outcomes. Journal of Consulting and Clinical Psychology. Advance online publication. <https://doi.org/10.1037/ccp0000930>

## Import

Import review-level reference and eligibility screening data in `2024_JCCP_Depression_Overview_Search_Data.xlsx`
* `reference_level`: One row per reference ID screened, abstract and eligibility decisions (all imported review citations)
* `review_bib`: One row per eligible review, main citation from Zotero for eligible reviews

```{r import-review-refs}
# Set path to search data
search_path <- (here(cwd, "2024_JCCP_Depression_Overview_Search_Data.xlsx"))

# Import reference_level excel sheet
reference_level <- read_excel(search_path, sheet = "reference_level",
                                      guess_max = 123456) 

# Import Zotero reference information for eligible reviews
review_bib <- bib2df(here(cwd, "2024_JCCP_included_reviews.bib")) %>% 
  janitor::clean_names()


```

Import additional eligibility data that was collected in DistillerSR after migrating from FileMaker.

```{r import-distiller-elig}
# Import additional eligibility data that was collected in DistillerSR
dpo_update_elig <- read_excel(here(cwd, "2024_JCCP_supplemental_eligibility.xlsx"), sheet = "eligibility") %>%
  janitor::clean_names()

```


Import primary study reference and eligibility screening data from `2024_JCCP_citation_matrix.xlsx`
 * `eligibility_decisions`: One row per primary study included in eligible reviews, data for eligibility decisions and reasons for exclude, when applicable
 * `reports`: One row per reference, data for multiple reports/citations of a single primary study, when applicable
 * `citation_matrix`: One row per primary study, data on primary study overlap (which primary studies were included in each review)

```{r import-excel-pselig}
# Set path to citation matrix and initial eligibility data
elig_path <- here(cwd, "2024_JCCP_citation_matrix.xlsx")

# Import eligibility_decisions sheet of excel file 
ps_eligibility <- read_excel(elig_path, sheet = "eligibility_decisions") 

# Import excel citation matrix (with header to calculate # of included/eligible studies)
ps_cm <- read_excel(elig_path, sheet = "citation_matrix")

# Import excel citation matrix sheet (without header to transpose for lists of included/eligible reviews)
citation_matrix <- read_excel(elig_path, sheet = "citation_matrix", col_names = FALSE)

```

Import reconciled, review-level data in `2024_JCCP_Depression_Overview_Review_Data.xlsx` from FileMaker
* `review_level`: One row per full-text-eligible review ID, extracted descriptive data at the review level
* `review_amstar`: One row per full-text-eligible review ID, extracted quality study assessment (AMSTAR) data
* `review_robis`: One row per full-text-eligible review ID, extracted risk of bias (ROBIS) data

```{r import-review}
# Set path to review-level data
rd_path <- here(cwd, "2024_JCCP_Depression_Overview_Review_Data.xlsx")

# Import review level descriptive data
review_level <- read_excel(rd_path, sheet = "review_level")

# Import review level quality study assessment data
review_amstar <- read_excel(rd_path, sheet = "amstar")

# Import review level risk of bias data
review_robis <- read_excel(rd_path, sheet = "robis")

```

Import additional data collected in DistillerSR after migrating from FileMaker

```{r import-review-distiller}
# Import update data from DistillerSR
rd_update_path <- here(cwd, "2024_JCCP_supplemental_review_data.xlsx")

review_level_update <- read_excel(rd_update_path, sheet = "review_descriptives") %>% 
  janitor::clean_names()
review_amstar_update <- read_excel(rd_update_path, sheet = "review_AMSTAR") %>% 
  janitor::clean_names()
review_robis_update <- read_excel(rd_update_path, sheet = "review_ROBIS") %>% 
  janitor::clean_names()

```

## Pre-processing

Reference Level:
* add leading numbers to all eligibility criteria reasons since some responses did not have them

```{r tidy-reference}
# Add leading numbers to harmonize responses
td_reference <- reference_level %>%
  mutate(exclude_reason = case_when(exclude_reason == "Ineligible due to anxiety focus only" ~
                                            "01. Ineligible due to anxiety focus only",
                                          exclude_reason == "Ineligible population (not K-12 students)" ~
                                            "02. Ineligible population (not K-12 students)",
                                          exclude_reason == "Ineligible interventions (not universal or secondary prevention)" ~
                                            "03. Ineligible interventions (not universal or secondary prevention)",
                                          exclude_reason == "Ineligible comparator (no comparator)" ~
                                            "04. Ineligible comparator (no comparator)",
                                          exclude_reason == "Ineligible outcomes (no depression outcomes)" ~
                                            "05. Ineligible outcomes (no depression outcomes)",
                                          exclude_reason == "Ineligible setting (not in school settings)" ~
                                            "07. Ineligible setting (not in school settings)",
                                          exclude_reason == "Ineligible study design (not a systematic review)" ~
                                            "08. Ineligible study design (not a systematic review)",
                                          exclude_reason == "Ineligible study design (no meta-analysis)" ~
                                            "09. Ineligible study design (no meta-analysis)",
                                          exclude_reason == "Ineligible publication type (not a full report)" ~
                                            "10. Ineligible publication type (not a full report)",
                                          exclude_reason == "Other reason (please specify in notes)" ~
                                            "11. Other reason (please specify in notes)",
                                          TRUE ~ exclude_reason)) %>%
  mutate_if(is.character, as.factor)

```

Review Level:
* create a new variable to identify reviews (extract author's last name and paste it with the year of publication)
* pull a list of the included reviews to use for filtering and merging
* merge review names into risk of bias data

```{r tidy-review}
# Create variable for author/year
td_review <- review_level %>% 
  mutate(review_author_lastname = str_extract(review_author_name, '\\w+$'),
         review_author_year = paste(review_author_lastname, review_year, sep = " ")) %>% 
  mutate(review_author_year = case_when(review_author_year == "Seidler 2017" ~ "Werner-Seidler 2017",
                                       review_author_year == "Seidler 2021" ~ "Werner-Seidler 2021",
                                       review_author_year == "Zoonen 2014" ~ "van Zoonen 2014",
                                       TRUE ~ review_author_year)) %>%  #correct parsing errors
  select(-review_author_lastname)

# Create data frame of review ids and review names (author/year)
review_idbyname <- td_review %>% 
  select(review_id, review_author_year)

# Pull list of included reviews
inc_rev <- review_idbyname$review_author_year
# Add reviews from update
inc_rev <- c(inc_rev, review_level_update$review_author_year)

# Merge review names into review_amstar data
td_amstar <- review_amstar %>% 
  left_join(review_idbyname) %>% 
  select(review_author_year, everything()) %>% 
  arrange(review_author_year) 

# Merge review names into review_robis data
td_robis <- review_robis %>%
  left_join(review_idbyname) %>%
  select(review_author_year, everything()) %>%
  arrange(review_author_year)

```

Primary Study Eligibility Level: 
* pull list of primary studies that are included in our meta-analyses (eligible studies)
* factor and rename the study name variable in the `citation_matrix` to match all other files

```{r tidy-pseligibility}
# Create object to match revision code
ps_elig_td <- ps_eligibility

# Pull list of included studies
inc_ps <- ps_eligibility %>%
  filter(decision == "Include") %>%
  pull(study)

# Create object to match merged code
td_cm <- ps_cm

```

Tidy additional data collected in DistillerSR

```{r tidy-supplemental}
# Tidy formatting
dpo_update_review_prisma <- dpo_update_elig %>% 
  mutate(review_elig_reason = case_when(eligibility_reference_type == "Study" ~ "Ineligible study design (not a systematic review)",
                                 review_exclude_reason == "Ineligible study design (not a systematic review or primary study)" ~ "Ineligible study design (not a systematic review)",
                                 str_detect(review_eligibility_notes, "could not locate|Unable to retrieve") ~ "Not retrieved", 
                                 TRUE ~ review_exclude_reason))

# Create a separate dataframe for expanded linked references
expanded_elig_df <- dpo_update_review_prisma %>%
  filter(!is.na(linked_references)) %>%
  separate_rows(linked_references, sep = ",\\s*") %>%
  filter(refid != linked_references) %>%
  mutate(refid = as.numeric(linked_references))

# Bind the expanded rows with the original dataframe
dpo_update_elig_long <- bind_rows(dpo_update_review_prisma, expanded_elig_df)

# Remove duplicates and reset row names
dpo_update_elig_long <- dpo_update_elig_long[!duplicated(dpo_update_elig_long), ]
rownames(dpo_update_elig_long) <- NULL

```

# Analysis Script for Results Section in Report

The following sections are organized to match the order in which results were presented in the report. The code to run the results for the narrative sections are presented first. Followed by the code to produce results for the figures, tables, and appendices.

## Narrative Results

This section includes the code to reproduce results in the narrative results section of the report. Each section heading of this document corresponds exactly to those in the narrative. 

### Eligibility Screening

This section includes code to reproduce the number of eligible reviews and studies. Unfortunately, there is not code to produce most of the numbers reported for the PRISMA flow diagram from our search since they were taken directly from DistillerSR and Zotero/FileMaker at the time of publication. At the time, we did not have a system in place for taking snapshots of all search or screening data from DistillerSR and cannot pull those retrospectively since we have continued to update our search and screening numbers for our living review. Numbers that were pulled directly from DistillerSR include:
> Number of records identified from search: 18,083
> Duplicates removed: 3,522
> Records screened: 14,561
> Records excluded: 12,235
> Reports sought for retrieval: 2,326
> Reports not retrieved: 21
> Reports assessed for eligibility: 2,305
> Reviews and reports (k) excluded (n = 2,268, k = 2,109):
>> Anxiety focus only (k = 154)
>> Ineligible population (k = 130)
>> Ineligible interventions (k = 868)
>> Ineligible comparator (k = 55)
>> Ineligible outcomes (k = 49)
>> Ineligible setting (k = 236)
>> Ineligible study design (k = 467)
>> Ineligible publication type (k = 114)
>> Unclear – need more details (k = 36)
> Reports included: k = 37


Number of eligible reviews: 

```{r elig-reviews}
# Create dataframe at the review level for reporting # of *reviews* from FileMaker
td_screen_review <- td_reference %>% 
  filter(!is.na(review_id)) %>% 
  distinct(review_id, .keep_all = TRUE)

# Calculate number of eligible *reviews* from initial FileMaker data and updated Distiller data
num_elig_reviews <- sum(td_screen_review$eligibility_consensus == "Eligible") + nrow(review_level_update)
num_elig_reviews

```

### Characteristics of Included Systematic Reviews


This section includes code to reproduce the quantitative results in the characteristics of included systematic reviews narrative results section.

Range and median of publication year across reviews:

```{r review-char-year}
# Calculate range and median for year published across reviews (combining results from update)
update_review_year <- c(review_level$review_year, review_level_update$review_publication_year)
range(update_review_year)
median(update_review_year)

```

Calculate most commonly searched databases

```{r review-char-databases}
## Calculate for review characteristics collected in FileMaker
# Change string to lowercase and create flag if each database was searched
rev_df <- review_level %>% 
  mutate(databases_searched = str_to_lower(databases_searched),
         pubmed = str_detect(databases_searched, "pubmed"),
         psycinfo = str_detect(databases_searched, "psycinfo"),
         medline = str_detect(databases_searched, "medline"),
         eric = str_detect(databases_searched, "eric"),
         eric2 = str_detect(databases_searched, "education resources information center"),
         ebsco = str_detect(databases_searched, "ebsco"),
         proquest_dt = str_detect(databases_searched, "dissertation and theses"),
         psycarticles = str_detect(databases_searched, "psycarticles"),
         psycextra = str_detect(databases_searched, "psycextra"),
         cochrance_central = str_detect(databases_searched, "cochrane central"),
         cochrane_library = str_detect(databases_searched, "cochrane library"),
         wos = str_detect(databases_searched, "web of science"),
         academic_ap = str_detect(databases_searched, "academic search premier"),
         pbs_collection = str_detect(databases_searched, "psychology and behavioral sciences collection"),
         cinahl = str_detect(databases_searched, "cinahl"),
         embase = str_detect(databases_searched, "embase"),
         science_cit_index = str_detect(databases_searched, "science citation index"),
         sci_direct = str_detect(databases_searched, "science direct"),
         scopus = str_detect(databases_searched, "scopus"),
         gscholar = str_detect(databases_searched, "google scholar"),
         british_ni = str_detect(databases_searched, "british nursing index"),
         britich_ei = str_detect(databases_searched, "british education index"),
         assia = str_detect(databases_searched, "assia"))

# Create long dataframe
review_databases <- rev_df %>% 
  select(review_id, pubmed:assia) %>% 
  pivot_longer(cols = pubmed:assia) %>% 
  left_join(review_idbyname) %>% 
  mutate(value = as.character(value))

# Calculate most common databases searched and 
# Remove cases where reviews said both pubmed and medline but only searched one
mode_databases <- review_databases %>% 
  mutate(name = case_when(name == "eric2" ~ "eric",
                          TRUE ~ name),
         value = case_when(review_author_year == "Bastounis 2016" & name == "medline" ~ "FALSE",
                           review_author_year == "Davaasambuu 2020" & name == "medline" ~ "FALSE",
                           TRUE ~ value)) %>% 
  group_by(name) %>% 
  summarize(num_db = sum(value == "TRUE"),
            percent = sum(value == "TRUE") / nrow(review_level) * 100) %>% 
  arrange(desc(num_db))
mode_databases 

## Calculate for additional Distiller data collection
rev_up_df <- review_level_update %>% 
  mutate(databases_searched = str_to_lower(review_databases_searched),
         pubmed = str_detect(databases_searched, "pubmed"),
         psycinfo = str_detect(databases_searched, "psycinfo"),
         medline = str_detect(databases_searched, "medline"),
         eric = str_detect(databases_searched, "eric"),
         eric2 = str_detect(databases_searched, "education resources information center"),
         ebsco = str_detect(databases_searched, "ebsco"),
         proquest_dt = str_detect(databases_searched, "dissertation and theses"),
         psycarticles = str_detect(databases_searched, "psycarticles"),
         psycextra = str_detect(databases_searched, "psycextra"),
         cochrance_central = str_detect(databases_searched, "cochrane central"),
         cochrane_library = str_detect(databases_searched, "cochrane library"),
         wos = str_detect(databases_searched, "web of science"),
         academic_ap = str_detect(databases_searched, "academic search premier"),
         pbs_collection = str_detect(databases_searched, "psychology and behavioral sciences collection"),
         cinahl = str_detect(databases_searched, "cinahl"),
         embase = str_detect(databases_searched, "embase"),
         science_cit_index = str_detect(databases_searched, "science citation index"),
         sci_direct = str_detect(databases_searched, "science direct"),
         scopus = str_detect(databases_searched, "scopus"),
         gscholar = str_detect(databases_searched, "google scholar"),
         british_ni = str_detect(databases_searched, "british nursing index"),
         britich_ei = str_detect(databases_searched, "british education index"),
         assia = str_detect(databases_searched, "assia")) %>% 
  select(refid, pubmed:assia) %>% 
  pivot_longer(cols = pubmed:assia) %>% 
  mutate(value = as.character(value)) %>% 
  group_by(name) %>% 
  summarize(num_db = sum(value == "TRUE"),
            percent = sum(value == "TRUE") / nrow(review_level) * 100) %>% 
  arrange(desc(num_db))

# Combine results
final_summary <- mode_databases %>%
  full_join(rev_up_df, by = "name", suffix = c("_rev", "_update")) %>%
  mutate(
    num_db_rev = replace_na(num_db_rev, 0),
    num_db_update = replace_na(num_db_update, 0),
    total_count = num_db_rev + num_db_update,
    total_percent = round((total_count / num_elig_reviews) * 100, 1) 
  ) %>%
  select(name, total_count, total_percent) %>%
  arrange(desc(total_count))
final_summary


```

Range and median of year of last database search: 

```{r review-char-databaseyear}
# Extract year from FileMaker search data
review_level <- review_level %>% 
  mutate(db_search_year = as.numeric(str_extract(search_date, "[0-9]{4}")))

# Extract year from update results
review_level_update <- review_level_update %>% 
  mutate(search_year = as.numeric(str_extract(review_search_date, "[0-9]{4}")))

# Combine
update_search_year <- c(review_level$db_search_year, review_level_update$search_year)
range(update_search_year, na.rm = TRUE)
median(update_search_year, na.rm = TRUE)

```

Number and percentage of reviews with PRISMA flow diagrams: 

```{r review-char-prisma}
# Calculate number and percent with flow diagrams (with initial and updated data)
prisma_count_rev <- sum(review_level$prisma_flow_diagram == "Yes", na.rm = TRUE)
prisma_count_update <- sum(review_level_update$review_flow_diagram == "Yes", na.rm = TRUE)

prisma_percent_rev <- (prisma_count_rev / nrow(review_level)) * 100
prisma_percent_update <- (prisma_count_update / nrow(review_level_update)) * 100

prisma_total_count <- prisma_count_rev + prisma_count_update
prisma_total_percent <- (prisma_total_count / (nrow(review_level) + nrow(review_level_update))) * 100

data.frame(
  Variable = c("Included PRISMA"),
  Count = c(prisma_total_count),
  Percent = round(c(prisma_total_percent), 1)
)

```

Number and percentage of reviews that reported a registration number:

```{r review-char-registration}
# Calculate number and % with registration number (with initial and updated data)
registration_count_rev <- sum(review_level$review_registration != "-999", na.rm = TRUE)
registration_count_update <- sum(review_level_update$review_registration_number != "-999", na.rm = TRUE)

registration_percent_rev <- (registration_count_rev / nrow(review_level)) * 100
registration_percent_update <- (registration_count_update / nrow(review_level_update)) * 100

registration_total_count <- registration_count_rev + registration_count_update
registration_total_percent <- (registration_total_count / (nrow(review_level) + nrow(review_level_update))) * 100

data.frame(
  Variable = c("Included registration"),
  Count = c(registration_total_count),
  Percent = round(c(registration_total_percent), 1)
)

```

Number and percentage of reviews that had a data availability statement: 

```{r review-char-availability}
# Calculate umber and % with availability statements (with initial and updated data)
availability_count_rev <- sum(review_level$review_availability_statement != "-999", na.rm = TRUE)
availability_count_update <- sum(review_level_update$review_availability_statement != "-999", na.rm = TRUE)

availability_percent_rev <- (availability_count_rev / nrow(review_level)) * 100
availability_percent_update <- (availability_count_update / nrow(review_level_update)) * 100

availability_total_count <- availability_count_rev + availability_count_update
availability_total_percent <- (availability_total_count / (nrow(review_level) + nrow(review_level_update))) * 100

data.frame(
  Variable = c("Included availablility statement"),
  Count = c(availability_total_count),
  Percent = round(c(availability_total_percent), 1)
) 

```

#### Overlap of Primary Studies Across Systematic Reviews

Range and median of number of primary studies included in each review (using citation matrix data):

```{r numperreview}
# Transpose data sing citation matrix without headers
cmt <- as.data.frame(t(citation_matrix))

# Save first row as new column names
colnames(cmt) <- cmt[1,]

# Remove first row of column names and second row with current study inclusions AND
# Create new variable to calculate number of studies in each review
df_overlap <- cmt %>% 
  slice(-1:-2) %>% 
  mutate(num_stud = rowSums(. == "1 - Yes")) 

# Calculate range and median of number of studies in each review
range(df_overlap$num_stud) 
median(df_overlap$num_stud) 

```

Number of primary studies included across all reviews: 

```{r elig-study}
# Extract number of primary studies across reviews
nrow(ps_elig_td)

```

Number and percentage of primary studies included in more than one review:

```{r morethanonereview}
# Create flag for if study is in more than one review
cm_overlap <- td_cm %>% 
  select(!`Current Review`) %>% 
  mutate(morethanone = ifelse(rowSums(. == "1 - Yes") >1, "yes", "no"))

# Calculate number and % included in more than one review
sum(cm_overlap$morethanone == "yes")
sum(cm_overlap$morethanone == "yes") / nrow(ps_elig_td) * 100

```

Number and percentage of primary studies that met our eligibility criteria (school-based depression interventions): 

```{r elig-inc-stud}
# Calculate number of included primary studies
sum(ps_elig_td$decision == "Include")
# Calclute percentage 
sum(ps_elig_td$decision == "Include") / nrow(ps_elig_td) * 100

```


Number and percentage of eligible primary studies included in more than one review:

```{r elig-morethanone}
# Filter for eligible primary studies
elig_cm <- td_cm %>% 
  select(-`Current Review`) %>% 
  filter(study %in% inc_ps) 

# Create flag if eligible study is included in more than one review
elig_overlap <- elig_cm %>% 
  mutate(morethanone = ifelse(rowSums(. == "1 - Yes") >1, "yes", "no"))

# Calculate number and % of eligible studies included in more than one review
sum(elig_overlap$morethanone == "yes") 
sum(elig_overlap$morethanone == "yes") / nrow(elig_overlap) * 100 

```

Overall CCA percentage for all primary studies included across reviews:

```{r ccaR-overlap}
# Create dataframe for ccaR input (1 = included; 0 = excluded)
ccar_input <- td_cm %>% 
  select(-`Current Review`) %>% 
  mutate_at(vars(-study), ~ifelse(. == "1 - Yes", 1, 0))  


# Calculate overall CCA
cca(ccar_input) 

```

Overall CCA percentage for primary studies meeting our eligibility criteria:

```{r ccaR-elig}
# Filter for only eligible studies
ccar_input_elig <- ccar_input %>% 
  filter(study %in% inc_ps)

# Calculate overall CCA
cca(ccar_input_elig) 

```

#### Methodological Quality of Included Systematic Reviews (AMSTAR-2)

Number and percentage of reviews that had *low* confidence ratings: 

```{r amstar-low}
# Calculate number of low confidence reviews (original and update)
num_am_low_rev <- sum(td_amstar$amstar_confidence_rating == "3. Low", na.rm = TRUE)
num_am_low_update <- sum(review_amstar_update$amstar_overall_rating == "LOW", na.rm = TRUE)

# Calculate total number of low confidence reviews
num_am_low_total <- num_am_low_rev + num_am_low_update

# Calculate total number and percent
data.frame(
  Number_Low = num_am_low_total,
  Percent_Low = round((num_am_low_total / (nrow(td_amstar) + nrow(review_amstar_update))) * 100, 1)
)


```

Number and percentage of reviews that had *critically low* confidence ratings: 

```{r amstar-critical-low}
# Calculate number of critically low confidence reviews (original and update)
num_am_cl_rev <- sum(td_amstar$amstar_confidence_rating == "4. Critically Low", na.rm = TRUE)
num_am_cl_update <- sum(review_amstar_update$amstar_overall_rating == "CRITICALLY LOW", na.rm = TRUE)

# Calculate total number of critically low confidence reviews
num_am_cl_total <- num_am_cl_rev + num_am_cl_update

# Calculate total number and percent
data.frame(
  Number_CLow = num_am_cl_total,
  Percent_CLow = round((num_am_cl_total / (nrow(td_amstar) + nrow(review_amstar_update))) * 100, 1)
)

```


Number and percentage of reviews that had *moderate* confidence ratings: 

```{r amstar-mod}
# Calculate number of moderate confidence reviews (original and update)
num_am_mod_rev <- sum(td_amstar$amstar_confidence_rating == "2. Moderate", na.rm = TRUE)
num_am_mod_update <- sum(review_amstar_update$amstar_overall_rating == "MODERATE", na.rm = TRUE)

# Calculate total number of moderate confidence reviews
num_am_mod_total <- num_am_mod_rev + num_am_mod_update

# Calculate total number and percent
data.frame(
  Number_Mod = num_am_mod_total,
  Percent_Mod = round((num_am_mod_total / (nrow(td_amstar) + nrow(review_amstar_update))) * 100, 1)
)


```

Number and percentage of reviews that had *high* confidence ratings: 

```{r amstar-high}
# Calculate number of high confidence reviews (original and update)
num_am_high_rev <- sum(td_amstar$amstar_confidence_rating == "1. High", na.rm = TRUE)
num_am_high_update <- sum(review_amstar_update$amstar_overall_rating == "HIGH", na.rm = TRUE)

# Calculate total number of high confidence reviews
num_am_high_total <- num_am_high_rev + num_am_high_update

# Calculate total number and percent
data.frame(
  Number_High = num_am_high_total,
  Percent_High = round((num_am_high_total / (nrow(td_amstar) + nrow(review_amstar_update))) * 100, 1)
)

```


Calculate most common critical weaknesses in AMSTAR ratings among reviews: 

```{r amstar-critical-domains}
# Select AMSTAR ratings (from both initial and update data)
amstar_ratings_fm <- td_amstar %>% 
  select(review_author_year, ends_with("rating"))

amstar_update_ratings <- review_amstar_update %>% 
  select(refid, study_name, ends_with("rating")) %>% 
  # Corrected amstar logic when there is an NRSI rating
  mutate(amstar_9_rating = ifelse(amstar_9nrsi_rating == "No", amstar_9nrsi_rating, amstar_9rct_rating),
         amstar_11_rating = ifelse(amstar_11nrsi_rating == "No", amstar_11nrsi_rating, amstar_11rct_rating)) %>% 
  select(-contains("nrsi"), -contains("rct"), -refid) %>% 
  rename(review_author_year = study_name,
         amstar_confidence_rating = amstar_overall_rating) %>% 
  relocate(amstar_9_rating, .before = "amstar_10_rating") %>% 
  relocate(amstar_11_rating, .after = "amstar_10_rating")

# Combine initial and update data
amstar_ratings <- rbind(amstar_ratings_fm, amstar_update_ratings)

# Change column names to match domain number
names(amstar_ratings) <- c("review_author_year", "1", "2", "3", "4", "5", "6", "7",
                          "8", "9", "10", "11", "12", "13", "14", "15", "16", "amstar_confidence_rating")

# Specify domain names
domain_names <- c(
  "2" = "Protocol registered before commencement of the review",
  "4" = "Adequacy of the literature search",
  "7" = "Justification for excluding individual studies",
  "9" = "Risk of bias from individual studies being included in the review",
  "11" = "Appropriateness of meta-analytical methods",
  "13" = "Consideration of risk of bias when interpreting the results of the review",
  "15" = "Assessment of presence and likely impact of publication bias")

# Filter for critical domains
amstar_crit <- amstar_ratings %>% 
  select(review_author_year, `2`, `4`, `7`, `9`, `11`, `13`, `15`) %>% 
  pivot_longer(cols = c("2", "4", "7", "9", "11", "13", "15")) %>% 
  mutate(name = recode(name, !!!domain_names))

# Calculate frequency for "No"s per critical domains
amstar_crit_mode <- amstar_crit %>% 
  group_by(name) %>% 
  summarize(n = sum(value == "No"),
            percent = sum(value == "No") / nrow(amstar_ratings) * 100) %>% 
  arrange(desc(n))
amstar_crit_mode

```


#### Risk of Bias in Included Systematic Reviews (ROBIS) 

Number and percentage of reviews with low risk of bias:

```{r robis-low}
# Calculate number/% of low risk
low_count <- sum(td_robis$robis_overall_rating == "2. Low") + 
             sum(review_robis_update$robis_overall_rating == "LOW")

total_nrow <- nrow(td_robis) + nrow(review_robis_update)

low_percentage <- round((low_count / total_nrow) * 100, 1)

low_count
low_percentage

```

Number and percentage of reviews with unclear risk of bias:

```{r robis-unclear}
# Calculate number/% of unclear risk
unclear_count <- sum(td_robis$robis_overall_rating == "3. Unclear") + 
             sum(review_robis_update$robis_overall_rating == "UNCLEAR")

total_nrow <- nrow(td_robis) + nrow(review_robis_update)

unclear_percentage <- round((unclear_count / total_nrow) * 100, 1)

unclear_count
unclear_percentage

```

Number and percentage of reviews with high risk of bias:

```{r robis-high}
# Calculate number/% of high risk
high_count <- sum(td_robis$robis_overall_rating == "1. High") + 
             sum(review_robis_update$robis_overall_rating == "HIGH")

total_nrow <- nrow(td_robis) + nrow(review_robis_update)

high_percentage <- round((high_count / total_nrow) * 100, 1)

high_count
high_percentage

```

Calculate the most common concerns about risk of bias among reviews:

```{r robis-common-concerns}
# Select ratings, transform to long format, calculate percent with high risk
robis_concerns_fm <- td_robis %>% 
  select(review_author_year, ends_with("decision"), robis_overall_a, 
         robis_overall_b, robis_overall_c, robis_overall_rating) 


robis_update_td <- review_robis_update %>% 
  select(study_name, ends_with("decision"), robis_overall_a, 
         robis_overall_b, robis_overall_c, robis_overall_rating) %>% 
  rename(review_author_year = study_name)

# Combine
robis_combined_df <- rbind(robis_concerns_fm, robis_update_td) %>% 
  arrange(review_author_year)

robis_concerns <- robis_combined_df %>% 
  select(-robis_overall_rating) %>% 
  pivot_longer(cols = 2:8) %>% 
  group_by(name) %>% 
  summarize(n_decision = sum(value %in% c("1. High", "HIGH")),
            per_decision = sum(value %in% c("1. High", "HIGH")) / nrow(robis_combined_df) * 100,
            n_overall = sum(value %in% c("4. No", "NO")),
            per_overall = sum(value %in% c("4. No", "NO")) / nrow(robis_combined_df) * 100) %>% 
  arrange(desc(n_decision)) 

# Specify domain names
robis_domain_names <- c(
  "robis_1_decision" = "Study eligibility criteria",
  "robis_2_decision" = "Identification and selection of studies",
  "robis_3_decision" = "Data collection and study appraisal",
  "robis_4_decision" = "Synthesis and findings",
  "robis_overall_a" = "Interpretation of findings addressed concerns",
  "robis_overall_b" = "Appropriately discussed the relevance of identified studies",
  "robis_overall_c" = "Avoid emphasizing results based on statistical significance")

robis_concerns_tbl <- robis_concerns %>% 
  mutate(name = recode(name, !!!robis_domain_names))


robis_concerns_tbl
  

```

### Findings from Eligible Systematic Reviews

These results were not calculated but taken directly from included reviews, therefore, there is no code to accompany this section. 

## Tables


### Table 1. Methodological Quality of Included Systematic Reviews according to AMSTAR-2 Assessments

Select AMSTAR ratings and format to present in table 1:

```{r amstar-table}
# Re-format ratings to report in table 1 (t2 from tech report)
t2 <- amstar_ratings %>% 
  mutate(review_author_year = as.factor(review_author_year)) %>% 
  mutate_if(is.character, ~case_when(. == "1. High" ~ "H",
                                     . == "2. Moderate" ~ "M",
                                     . == "3. Low" | . == "LOW" ~ "L",
                                     . == "4. Critically Low" | . == "CRITICALLY LOW" ~ "CL",
                                     . == "Yes" ~ "Y",
                                     . == "Partial yes" | . == "Partial Yes" ~ "PY",
                                     . == "No" ~ "N",
                                     TRUE ~ .)) %>% 
  arrange(str_to_lower(review_author_year))

```

Create table 1 and format:

```{r t2-format}
# Create gt table and format
t2_formatted <- t2 %>% 
  gt() %>% 
  cols_label(review_author_year = "Review", 
             amstar_confidence_rating = "Overall") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
  tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.border.bottom.color = "white",
              table.font.names = "Times New Roman") %>% 
  cols_width(review_author_year ~ px(175),
             amstar_confidence_rating ~ px(75),
             everything() ~ px(35)) %>% 
  tab_style(style = cell_text(align = "center"), locations = cells_column_labels(columns = everything())) %>% 
  tab_style(style = cell_text(align = "left"), locations = cells_column_labels(columns = "review_author_year")) %>% 
  tab_style(style = cell_text(align = "center"), locations = cells_body(columns = everything())) %>% 
  tab_style(style = cell_text(align = "left"), locations = cells_body(columns = "review_author_year")) %>% 
  tab_footnote(footnote = "N = No; PY = Partial Yes; Y = Yes; CL = Critically Low; L = Low; M = Moderate; H = High") %>% 
  data_color(
    columns = 2:18,
    colors = scales::col_factor(
      palette = c("#ab1d1a", "#8ace7e", "#e03531", "#ffda66", "#e03531", "#b2dfa8", "#8ace7e"),
      domain = c("CL", "H", "L", "M", "N", "PY", "Y")
    )
  )

          
print(t2_formatted)

```

Save table 1 to `outputs/tables`` project folder: 

```{r save-t2}
# Set output directory
outputs_dir <- here("publications", "2024_JCCP", "outputs")

# Save as HTML
gtsave(t2_formatted, filename = "2024_JCCP_table1.html", path = outputs_dir)

# Save as word doc
#gtsave(t2_formatted, filename = "table1_word.docx")

```

### Table 2. Risk of Bias in Included Systematic Reviews according to ROBIS Assessments

Format rankings for reporting in table: 

```{r robis-table}
# Remove leading numbers, select variables (from t3 tech report)
t3 <- robis_combined_df %>% 
    mutate_if(is.character, ~case_when(. == "1. High" | . == "HIGH" ~ "High",
                                     . == "2. Low" | . == "LOW" ~ "Low",
                                     . == "3. Unclear" | . == "UNCLEAR" ~ "Unclear",
                                     . == "1. Yes" ~ "Yes",
                                     . == "2. Probably Yes" ~ "Probably Yes",
                                     . == "3. Probably No" ~ "Probably No",
                                     . == "4. No" ~ "No",
                                     . == "5. No information" ~ "No Information",
                                     TRUE ~ .)) %>% 
  select(review_author_year, ends_with("decision"), robis_overall_a, robis_overall_b, robis_overall_c, robis_overall_rating) %>% 
  arrange(str_to_lower(review_author_year))

```

Create table 2 and format table:

```{r t3-format}
# Create gt table
t3_formatted <- t3 %>% 
  gt() %>% 
  cols_label(review_author_year = "Review", 
             robis_1_decision = "Domain 1",
             robis_2_decision = "Domain 2",
             robis_3_decision = "Domain 3",
             robis_4_decision = "Domain 4",
             robis_overall_a = "Interpretation",
             robis_overall_b = "Relevance",
             robis_overall_c = "Spin",
             robis_overall_rating = "Overall") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
   tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.border.bottom.color = "white",
              table.font.names = "Times New Roman") %>% 
   cols_width(review_author_year ~ px(150),
              robis_overall_a ~ px(110),
              robis_overall_b ~ px(100),
              robis_overall_c ~ px(100),
              everything() ~ px(100),
              robis_overall_rating ~ px(50)) %>% 
  data_color(columns = 2:9,
             colors = scales::col_factor(palette = c("#e03531", "#8ace7e", "#e03531", "gray60", "#ef9997", "#b2dfa8", "#ffda66", "#8ace7e"),
                                         domain = c("High", "Low", "No", "No Information", "Probably No", "Probably Yes", "Unclear", "Yes")))


print(t3_formatted)

```

Save table 2 to `outputs/tables`` project folder: 

```{r t3-save}
# Save as html
gtsave(t3_formatted, filename = "2024_JCCP_table2.html", path = outputs_dir)

# Save as word doc
#gtsave(t3_formatted, filename = "table2_word.docx")

```

### Table 3. Meta-Analytic Effect Estimates for School-Based Depression Prevention Interventions Overall

Table 3 was created by extracting information directly from included reviews to produce the table for publication. At the time of publication, we were not collecting this information in a data file format to reproduce table 3 via code.

## Figures

### Figure 1. Flow diagram for identification of systematic reviews and primary studies

As mentioned above in the "Eligibility Screening" section, there is not code to produce the PRISMA flow diagram since most eligibility and search numbers were taken directly from multiple sources (DistillerSR, Zotero, FileMaker) at the time of publication. 

### Figure 2. Overlap of all primary studies across systematic reviews

Create CCA heatmap of overlap of included studies across reviews:

```{r ccaR-f2}
# Format citation matrix including our review
cca_inc <- td_cm %>% 
  mutate_at(vars(-study), ~ifelse(. == "1 - Yes", 1, 0)) %>% 
  rename(` Current Review` = `Current Review`) 

# Create pairwise heatmap with CCA(%), including our review
f2 <- cca_heatmap(cca_inc, decimal_digits = 0, fontsize = 4.5, fontsize_diag = 3) +
  ggplot2::theme(
      plot.caption = ggplot2::element_text(size = 16, margin=ggplot2::margin(30,0,0,0)),
      legend.title = ggplot2::element_text(size = 16, face = "bold", vjust=4),
      legend.text = ggplot2::element_text(size = 16),
      legend.key.size = ggplot2::unit(1.0, "cm"),
      legend.title.align = 0.5,
      legend.text.align = 0.5,
      axis.text.x=ggplot2::element_text(size = 16),
      axis.text.y=ggplot2::element_text(size = 16),
      axis.title=ggplot2::element_blank(),
      axis.ticks=ggplot2::element_blank(),
      axis.line=ggplot2::element_blank(),
      panel.border=ggplot2::element_blank(),
      panel.grid.major.x=ggplot2::element_line(colour = "grey80", linetype = "dashed"))

f2

```

Save figure 2 to `outputs/figures` project folder: 

```{r save-f2}
# Set image dimensions and file path to save
png(here(outputs_dir, "2024_JCCP_figure2.png"), width = 1000, height = 1000)

# Show plot
f2

# Save png of plot
dev.off()
```

### Figure 3. Overlap of eligible studies across systematic reviews

Filter for studies that met our inclusion criteria and create CCA heatmap of our eligible studies across reviews: 

```{r ccaR-elig-f3}
# Format citation matrix of eligible studies, including our review
cca_elig <- td_cm %>% 
  filter(study %in% inc_ps) %>% 
  mutate_at(vars(-study), ~ifelse(. == "1 - Yes", 1, 0))  %>% 
  rename(` Current Review` = `Current Review`)

# Create pairwise heatmap with CCA(%)
f3 <- cca_heatmap(cca_elig, decimal_digits = 0, fontsize = 4.5, fontsize_diag = 3.2) +
  ggplot2::theme(
      plot.caption = ggplot2::element_text(size = 16, margin=ggplot2::margin(30,0,0,0)),
      legend.title = ggplot2::element_text(size = 16, face = "bold", vjust=4),
      legend.text = ggplot2::element_text(size = 16),
      legend.key.size = ggplot2::unit(1.0, "cm"),
      legend.title.align = 0.5,
      legend.text.align = 0.5,
      axis.text.x = ggplot2::element_text(size = 16),
      axis.text.y = ggplot2::element_text(size = 16),
      axis.title = ggplot2::element_blank(),
      axis.ticks = ggplot2::element_blank(),
      axis.line = ggplot2::element_blank(),
      panel.border = ggplot2::element_blank(),
      panel.grid.major.x = ggplot2::element_line(colour = "grey80", linetype = "dashed"))

print(f3)

```

Save figure 3 to `outputs/figures` project folder: 

```{r save-f3}
# Set image dimensions and file path to save
png(here(outputs_dir, "2024_JCCP_figure3.png"), width = 1000, height = 1000)

# Show plot
f3

# Save png of plot
dev.off()
```

## Supplements

### Supplement 2. List of excluded reviews

Create data frame with info for Supplement 2. List of excluded reviews at the full-text eligibility stage (excluded review & reason):

```{r list-excl-review}
# Using FileMaker reference level data, extract author/year from citation
fm_ref <- td_reference %>% 
  mutate(author = str_extract(citation, "^\\S+"),
         authornocom = str_replace(author, ",", ""),
         author_full = str_extract(citation, "^([^,(]*)"),
         year = str_extract(citation, "[0-9]{4}"),
         author_year = paste(author_full, year, sep = " "))

# Select not eligible studies and columns of info to report in appendix 1
a1_info <- fm_ref %>% 
  filter(eligibility_consensus == "Review Not Eligible" | eligibility_consensus == "Not Eligible") %>% 
  mutate(exclude_reason = str_extract(exclude_reason, "(?<=\\.)\\s+(.*)")) %>% 
  select(author_year, exclude_reason, screening_id, citation) %>% #, screening_id, citation #->took out to merge
  arrange(author_year)

# Add update review data from DistillerSR and fix review names
a1_info_update <- dpo_update_review_prisma %>% 
  filter(!is.na(review_elig_reason)) %>% 
  mutate(author_year = str_remove(bibliography, ", et al"),
         author_year = str_replace(author_year, "(^[A-Za-z][^/]*)/.*", "\\1")) %>% 
  rename(exclude_reason = review_elig_reason) %>% 
  select(author_year, exclude_reason) %>% 
  #remove clinical trials
  filter(author_year!= "#Year#",
         !str_detect(author_year, "^[0-9]"))

# Correct review names that parsed incorrectly from incorrect citation
a1 <- a1_info %>% 
  mutate(author_year = case_when(author_year == " 2006" ~ "Venning 2006",
                                 author_year == " 2010" ~ "Anttila 2010",
                                 author_year == "Abdelfettah Elkchirid PhD 2022" ~ "Elkchirid 2022",
                                 author_year == "Alba‐Elena Martinez‐Santos 2021" ~ "Martinez‐Santos 2021",
                                 author_year == "Anonymous  2022" ~ "Steains 2021",
                                 author_year == "Anonymous  2011" ~ "Teubert 2011",
                                 author_year == "Bevan Jones 2018" ~ "Bevan-Jones 2018",
                                 author_year == "Brown 2018" ~ "Brown 2018a",
                                 author_year == "C Hendricks Brown 2018" ~ "Brown 2018b",
                                 author_year == "Julian Edbrooke‐Childs 2021" ~ "Edbrooke‐Childs 2021",
                                 author_year == "Joelle Yan Xin Chua 2020" ~ "Chua 2020",
                                 author_year == "Josefa González Moller 2021" ~ "Moller 2021",
                                 author_year == "Latefa Ali Dardas 2018" ~ "Dardas 2018",
                                 author_year == "Negreiros de Carvalho 2021" ~ "Carvalho 2021",
                                 author_year == "Soneson Emma 2020" ~ "Soneson 2020",
                                 author_year == "Sun Jae Moon 2020" ~ "Moon 2020",
                                 author_year == "Sylvia Deidre Kauer 2014" ~ "Kauer 2014",
                                 author_year == "Zarakoviti Eleni 2021" ~ "Zarakoviti 2021",
                                 TRUE ~ author_year)) %>% 
  select(author_year, exclude_reason) %>% 
  #update with update data - Jan 2024
  bind_rows(a1_info_update) %>% 
  
  arrange(str_to_lower(stringi::stri_trans_general(author_year, "Latin-ASCII")))

```

Create table for appendix 1 and format: 

```{r a1-tableformat}
# Create gt table and format
a1_formatted <- a1 %>% 
  gt()  %>% 
  cols_label(author_year = "Excluded Review", 
             exclude_reason = "Reason for Exclusion") %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1))),
            locations = cells_body(columns = everything())) %>% 
  tab_style(style = list(cell_borders(sides = "all", color = "black", weight = px(1)),
                         cell_text(weight = "bold")),
            locations = cells_column_labels()) %>% 
  tab_options(column_labels.border.top.color = "black",
              column_labels.border.bottom.color = "black",
              table_body.border.bottom.color = "black",
              table.border.top.color = "white",
              heading.border.bottom.color = "black",
              table_body.hlines.color = "white",
              table.border.bottom.color = "white",
              table.font.names = "Times New Roman") %>% 
  tab_header(title = md("**Supplement 2. List of Excluded Reviews**"))

print(a1_formatted)

```

Save supplement 2 to `outputs` project folder: 

```{r save-a1}
# Save as word
#gtsave(a1_formatted, filename = "update_s2_word.docx")

# Save as html
gtsave(a1_formatted, filename = "2024_JCCP_supplement2.html", path = here(outputs_dir))

```


### Supplement 3. Descriptive characteristics for each included systematic review 

Select information to display in Supplement 3 (descriptive characteristics for each included systematic review) and format data for table:

Calculate the number of included and eligible studies per review:

```{r numstud-perreview}
# Transform to long to calculate # of included/eligible studies per review
cm_long <- td_cm %>% 
  select(-`Current Review`) %>% 
  pivot_longer(cols = `Ahlen 2015`:`Zheng 2023`,
               names_to = "review_author_year") 

# Count number of included studies per review
numinc_perreview <- cm_long %>% 
  group_by(review_author_year) %>% 
  summarize(n_included = sum(value == "1 - Yes", na.rm = TRUE)) %>% 
  ungroup()

# Count number of eligible studies per review
numelig_perreview <- cm_long %>% 
  filter(study %in% inc_ps) %>% 
  group_by(review_author_year) %>% 
  summarize(n_eligible = sum(value == "1 - Yes", na.rm = TRUE)) %>% 
  ungroup()

```

```{r per-review-descriptives, warning = FALSE}
# Extract names from FileMaker data
names_fm_review <- names(td_review)

# Filter distiller data based on FM names
td_review_update <- review_level_update %>% 
  rename(review_id = refid,
         review_author_name = review_cor_author,
         review_author_institute = review_cor_institute,
         review_author_email = review_cor_email, 
         review_year = review_publication_year,
         databases_searched = review_databases_searched,
         search_date = review_search_date,
         number_studies = review_number_studies, 
         prisma_flow_diagram = review_flow_diagram,
         review_registration = review_registration_number,
         db_search_year = search_year) %>% 
  mutate(across(c(review_year, number_studies), as.numeric)) %>% 
  select(all_of(names_fm_review))

# Append Distiller update date to initial FileMaker data 
td_review_full <- bind_rows(td_review, td_review_update)
 

# Select relevant appendix 4 info
a4_info <- td_review_full %>% 
  left_join(numelig_perreview) %>% 
  left_join(numinc_perreview) %>% 
  mutate(search_date = ifelse(nchar(search_date) == 10, format(ymd(search_date), "%B %d, %Y"), search_date)) %>% 
  mutate(search_date = ifelse(nchar(search_date) == 7, format(ym(search_date), "%B %Y"), search_date)) %>% 
  mutate(across(everything(), ~ifelse(.x == -999, "Not reported", .x)),
         n_included = as.character(n_included),
         n_eligible = as.character(n_eligible)) %>% 
  select(review_author_year, starts_with("review_eligibility"), databases_searched, 
         search_date, n_included, n_eligible, prisma_flow_diagram, review_registration, review_availability_statement) %>% 
  arrange(str_to_lower(review_author_year)) 

# Select citation info for eligible reviews
review_citations <- td_reference %>% 
  left_join(review_idbyname) %>% 
  filter(review_author_year %in% inc_rev) %>% 
  select(review_author_year, citation) %>% 
  # Bind with update data
  bind_rows(
    review_level_update %>%
      select(review_author_year, bibliography) %>%
      rename(citation = bibliography))

# Create variable that combines all references for a review into one cell
review_reports <- review_citations %>% 
  group_by(review_author_year) %>% 
  summarize(all_reports = paste(citation, collapse = " !!! ")) %>% 
  ungroup() %>% 
  mutate(all_reports = str_replace_all(all_reports, "!!! ", "<br><br>"),
         merge_author = stri_trans_general(review_author_year, "Latin-ASCII"),
         merge_author = str_to_lower(merge_author)) %>% 
  select(review_author_year, merge_author, all_reports)

# Extract titles from .bib
rev_titles <- review_bib %>% 
    rowwise() %>% 
  mutate(author_unlist = paste(lapply(author, paste, collapse = ","), collapse = ", "),
         author = str_extract(author_unlist, "^[^,]+"),
         author_year = paste(author, year), 
         title = str_replace_all(title, "[{}]", ""),
         title = str_remove(title, "\\.$"),
         merge_author = stri_trans_general(author_year, "Latin-ASCII"),
         merge_author = str_to_lower(merge_author)) %>% 
  select(author_year, merge_author, title) %>% 
  arrange(str_to_lower(author_year)) %>% 
  # Bind titles from review_level_update
  bind_rows(
    review_level_update %>%
      select(review_author_year, title) %>%
      rename(author_year = review_author_year) %>%
      mutate(merge_author = stri_trans_general(author_year, "Latin-ASCII"),
             merge_author = str_to_lower(merge_author)))

# Merge titles and citations with other a4 info and format eligibility cells
a4 <- a4_info %>% 
  mutate(merge_author = stri_trans_general(review_author_year, "Latin-ASCII"),
         merge_author = str_to_lower(merge_author)) %>% 
  left_join(rev_titles, by = "merge_author") %>% 
  left_join(review_reports, by = "merge_author") %>% 
  mutate_at(vars(starts_with("review_eligibility")), list(~ str_replace_all(., "\\s-\\s(?=[A-Z])", "<br> - "))) %>% 
  mutate_at(vars(starts_with("review_eligibility")), ~ str_replace_all(., "- ([A-Z])", " <li>\\1")) %>% 
  mutate_at(vars(starts_with("review_eligibility")), ~ paste0("<ul>", ., "</ul>")) %>% 
  rename(review_author_year = review_author_year.x) %>% 
  select(review_author_year, title, review_eligibility_participants:review_availability_statement, all_reports)
  
```

Create one long data frame that has all information to present in appendix 4 for each review:

```{r a4-mapdf}
# Split data frame into list of data frames
a4_dflist <- map(1:nrow(a4), ~a4[.x, ])

# Transfer to long format
df_list_long <- map(a4_dflist, ~ .x %>% 
                      pivot_longer(cols = everything(), 
                                   names_to = "variable", 
                                   values_to = "value") %>% 
                      mutate(variable = case_when(variable == "review_author_year" ~ "Review",
                                                  variable == "title" ~ "Title",
                                                  variable == "review_eligibility_participants" ~ "Participants",
                                                  variable == "review_eligibility_interventions" ~ "Interventions",
                                                  variable == "review_eligibility_comparisons" ~ "Comparisons",
                                                  variable == "review_eligibility_outcomes" ~ "Outcomes",
                                                  variable == "review_eligibility_timing" ~ "Timing",
                                                  variable == "review_eligibility_setting" ~ "Setting",
                                                  variable == "review_eligibility_studies" ~ "Studies",
                                                  variable == "databases_searched" ~ "Databases Searched",
                                                  variable == "search_date" ~ "Search Date",
                                                  variable == "prisma_flow_diagram" ~ "Prisma Diagram", 
                                                  variable == "review_registration" ~ "Registration",
                                                  variable == "review_availability_statement" ~ "Data Availability Statement",
                                                  variable == "n_eligible" ~ "Eligible Studies",
                                                  variable == "n_included" ~ "Included Studies",
                                                  variable == "all_reports" ~ "References",
                                                  TRUE ~ variable)))
  
# Combine into one single data frame
combined_a4 <- bind_rows(df_list_long, .id = "source") %>% 
  mutate(source = as.numeric(source))

```

Create list of tables for each review to present in appendix 4: 

```{r a4-maptable, results ='asis'}
# Create gt table for each for each review
list_gt <- lapply(split(combined_a4, combined_a4$source), function(x) {
  x <- x %>%
    mutate(across(c(variable, value), as.character)) # Convert to character

  gt(x) %>%
    cols_hide("source") %>%
    cols_label(variable = "",
               value = "") %>%
    tab_style(style = list(cell_text(weight = "bold")),
              locations = cells_body(columns = "variable")) %>%
    tab_row_group(rows = 3:9, label = "Eligibility Criteria:") %>%
    tab_row_group(rows = 1:2, label = "", id = "group1") %>%
    tab_options(table.font.names = "Times New Roman") %>%
    tab_style(style = cell_text(weight = "bold"), locations = cells_row_groups()) %>%
    tab_style(style = cell_text(align = "right"), locations = cells_body(columns = "variable", rows = 3:9)) %>%
    fmt_markdown(columns = c(variable, value)) # Apply markdown only to text columns
})


# Extract HTML code of table
html_code <- list_gt %>% 
  map(as_raw_html) %>% 
  reduce(paste)

# Print in document
htmltools::browsable(htmltools::HTML(html_code))


```

Save supplement 3 to `outputs` project folder: 

```{r a4-save}
# Save as HMTL
writeLines(html_code, here(outputs_dir, "2024_JCCP_supplement3.html"))

#output to excel and import into word
#rio::export(combined_a4, "initial_a4_excel.xlsx")


```


# END